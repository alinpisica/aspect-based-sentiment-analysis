{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from semeval_reader import SemevalReader\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from sa_models.SA_BERT_Dropout_Linear import SA_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_list_for_polarity(polarity):\n",
    "    if polarity == 'positive':\n",
    "        return [0, 0, 1]\n",
    "    if polarity == 'negative':\n",
    "        return [1, 0, 0]\n",
    "    return [0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_reader = SemevalReader('../../../data/semeval16_restaurants_train.xml')\n",
    "\n",
    "reviews = semeval_reader.read_reviews()\n",
    "absolute_polarity_sentences = semeval_reader.get_absolute_polarity_sentences()\n",
    "\n",
    "df = pd.DataFrame(map(lambda x: (x.text, x.opinions[0].polarity), absolute_polarity_sentences))\n",
    "df.rename(columns={0: 'text'}, inplace=True)\n",
    "df['target_list'] = df.apply(lambda row: get_target_list_for_polarity(row[1]), axis=1)\n",
    "\n",
    "absolute_polarity_df = df.drop(columns=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/SA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/SA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/SA/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.8918753862380981\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.389412522315979\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.44718050956726074\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.4466648995876312\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.1541673243045807\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.08768513053655624\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.06189978867769241\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.20630936324596405\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.44148629903793335\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.37325018644332886\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.09487621486186981\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.052659790962934494\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.10004114359617233\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.07608499377965927\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.05242089554667473\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.026612553745508194\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.03166494891047478\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.06774662435054779\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.05319006368517876\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.029781026765704155\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.038821496069431305\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.022337934002280235\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.6748466491699219\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.4495032727718353\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.28112566471099854\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.4567636251449585\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.40484094619750977\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.12601874768733978\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.5480138659477234\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.08024714887142181\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.07813398540019989\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.06194458156824112\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.07498014718294144\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.06044478341937065\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.09449222683906555\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.049393586814403534\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.04932058975100517\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.18238644301891327\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.03062620759010315\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.02757721208035946\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.03304612636566162\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.03689572587609291\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.2837129533290863\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.04734162613749504\n",
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.6576308012008667\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.3278726041316986\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.24290691316127777\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.13936123251914978\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.10494230687618256\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.42435258626937866\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.10334636270999908\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.0650082379579544\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.07554037868976593\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.0490032434463501\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.20022910833358765\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.0574282631278038\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.4269614815711975\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.06703893840312958\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.043449968099594116\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.019945984706282616\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.11743567883968353\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.04664979875087738\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.04316467046737671\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.03339218348264694\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.11732009053230286\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.025693565607070923\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.8083130717277527\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.4046251177787781\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.5272805690765381\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.23363052308559418\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.1500483751296997\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.10365693271160126\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.42953866720199585\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.09446405619382858\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.2945341169834137\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.0541696771979332\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.054534606635570526\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.07998794317245483\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.07802005112171173\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.03352761268615723\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.33874082565307617\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.05810941010713577\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.026066293939948082\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.037726908922195435\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.20059096813201904\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.02158912643790245\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.024172402918338776\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.033714693039655685\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.7197217345237732\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.5337668657302856\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.23217210173606873\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.14761552214622498\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.46242809295654297\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.09969289600849152\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.11965973675251007\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.07371191680431366\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.056310564279556274\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.10262072086334229\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.03568948805332184\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.06368342787027359\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.04675964638590813\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.07238414883613586\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.025537461042404175\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.25855422019958496\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.053123801946640015\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.019999351352453232\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.02284807339310646\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.035654760897159576\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.018553849309682846\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.3225979208946228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.5273030996322632\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.2976996600627899\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.4517795443534851\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.17993727326393127\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.16028423607349396\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.6299176216125488\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.09512168169021606\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.08708690106868744\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.06157172843813896\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.2823922634124756\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.050207287073135376\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.04275844618678093\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.034653231501579285\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.37641841173171997\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.14036570489406586\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.053934261202812195\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.0366075299680233\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.04006796330213547\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.021584099158644676\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.02799638733267784\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.015559662133455276\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.03019982948899269\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.6642069220542908\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.3449432849884033\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.5190945863723755\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.09948289394378662\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.13959310948848724\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.08912532031536102\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.08286555856466293\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.0632920190691948\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.12183542549610138\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.07179892063140869\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.12416358292102814\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.06785920262336731\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.04040006920695305\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.04481784626841545\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.028584253042936325\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.030011510476469994\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.04345453530550003\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.027694419026374817\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.024756349623203278\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.03020281158387661\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.033567219972610474\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.03815422207117081\n",
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.5932226777076721\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.4822307825088501\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.2500540018081665\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.20473432540893555\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.15696266293525696\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.11030785739421844\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.06341799348592758\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.7397343516349792\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.04126402735710144\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.06366418302059174\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.054781343787908554\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.2588956952095032\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.04492376744747162\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.03858498856425285\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.03358374163508415\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.01691228523850441\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.05714647099375725\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.015799790620803833\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.03883001208305359\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.057469286024570465\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.03416363149881363\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.024196496233344078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.5749421119689941\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.34619542956352234\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.2050846815109253\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.47545886039733887\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.0705590695142746\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.37134480476379395\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.34952616691589355\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.30032044649124146\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.06720657646656036\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.03426608443260193\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.06050623580813408\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.1882946789264679\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.05629577487707138\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.033900514245033264\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.03662695735692978\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.04080123454332352\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.02166314423084259\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.09928711503744125\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.5456985831260681\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.028423896059393883\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.05063330754637718\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.027836646884679794\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/313, Loss: 0.6697027087211609\n",
      "Epoch: 0/2, Batch: 31/313, Loss: 0.39932966232299805\n",
      "Epoch: 0/2, Batch: 62/313, Loss: 0.19008585810661316\n",
      "Epoch: 0/2, Batch: 93/313, Loss: 0.19675271213054657\n",
      "Epoch: 0/2, Batch: 124/313, Loss: 0.1455409973859787\n",
      "Epoch: 0/2, Batch: 155/313, Loss: 0.08604820817708969\n",
      "Epoch: 0/2, Batch: 186/313, Loss: 0.08256450295448303\n",
      "Epoch: 0/2, Batch: 217/313, Loss: 0.048935696482658386\n",
      "Epoch: 0/2, Batch: 248/313, Loss: 0.04497580975294113\n",
      "Epoch: 0/2, Batch: 279/313, Loss: 0.07951786369085312\n",
      "Epoch: 0/2, Batch: 310/313, Loss: 0.209759920835495\n",
      "Epoch: 1/2, Batch: 0/313, Loss: 0.06253717839717865\n",
      "Epoch: 1/2, Batch: 31/313, Loss: 0.03915316238999367\n",
      "Epoch: 1/2, Batch: 62/313, Loss: 0.04624173790216446\n",
      "Epoch: 1/2, Batch: 93/313, Loss: 0.03361521288752556\n",
      "Epoch: 1/2, Batch: 124/313, Loss: 0.027297478169202805\n",
      "Epoch: 1/2, Batch: 155/313, Loss: 0.1380024552345276\n",
      "Epoch: 1/2, Batch: 186/313, Loss: 0.024323895573616028\n",
      "Epoch: 1/2, Batch: 217/313, Loss: 0.06173783540725708\n",
      "Epoch: 1/2, Batch: 248/313, Loss: 0.023295503109693527\n",
      "Epoch: 1/2, Batch: 279/313, Loss: 0.09835513681173325\n",
      "Epoch: 1/2, Batch: 310/313, Loss: 0.031115390360355377\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/10\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True\n",
    "    )\n",
    "\n",
    "    model = SA_BERT_Dropout_Linear(torch.load(BERT_FINE_TUNED_PATH), dropout=0.3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    targets = np.argmax(targets, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.956388</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.684895</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.697263</td>\n",
       "      <td>200.450585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.952768</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.726105</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.755830</td>\n",
       "      <td>195.854452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.687908</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.693350</td>\n",
       "      <td>194.716570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.932640</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.664640</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.660842</td>\n",
       "      <td>194.679791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.616116</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.649236</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.632201</td>\n",
       "      <td>194.734065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.750440</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.692844</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.708917</td>\n",
       "      <td>194.740792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.947947</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.678760</td>\n",
       "      <td>0.939103</td>\n",
       "      <td>0.678013</td>\n",
       "      <td>194.728948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.649388</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.620402</td>\n",
       "      <td>194.549264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.953641</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.723351</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.757983</td>\n",
       "      <td>194.336836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.960974</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.719728</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.751210</td>\n",
       "      <td>194.689570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.948718               0.948718               0.956388            0.948718   \n",
       "1  0.951923               0.951923               0.952768            0.951923   \n",
       "2  0.951923               0.951923               0.959196            0.951923   \n",
       "3  0.923077               0.923077               0.932640            0.923077   \n",
       "4  0.939103               0.939103               0.616116            0.939103   \n",
       "5  0.955128               0.955128               0.750440            0.955128   \n",
       "6  0.939103               0.939103               0.947947            0.939103   \n",
       "7  0.919872               0.919872               0.596154            0.919872   \n",
       "8  0.942308               0.942308               0.953641            0.942308   \n",
       "9  0.948718               0.948718               0.960974            0.948718   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.684895        0.948718        0.697263      200.450585  \n",
       "1            0.726105        0.951923        0.755830      195.854452  \n",
       "2            0.687908        0.951923        0.693350      194.716570  \n",
       "3            0.664640        0.923077        0.660842      194.679791  \n",
       "4            0.649236        0.939103        0.632201      194.734065  \n",
       "5            0.692844        0.955128        0.708917      194.740792  \n",
       "6            0.678760        0.939103        0.678013      194.728948  \n",
       "7            0.649388        0.919872        0.620402      194.549264  \n",
       "8            0.723351        0.942308        0.757983      194.336836  \n",
       "9            0.719728        0.948718        0.751210      194.689570  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
