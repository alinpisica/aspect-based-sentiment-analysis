{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_CNN_BiLSTM_Linear import ABSA_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_MAMS_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The decor is not special at all but their food...</td>\n",
       "      <td>[The, decor, is, not, special, at, all, but, t...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The decor is not special at all but their food...</td>\n",
       "      <td>[The, decor, is, not, special, at, all, but, t...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The decor is not special at all but their food...</td>\n",
       "      <td>[The, decor, is, not, special, at, all, but, t...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when tables opened up, the manager sat another...</td>\n",
       "      <td>[when, tables, opened, up, ,, the, manager, sa...</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>when tables opened up, the manager sat another...</td>\n",
       "      <td>[when, tables, opened, up, ,, the, manager, sa...</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The decor is not special at all but their food...   \n",
       "1  The decor is not special at all but their food...   \n",
       "2  The decor is not special at all but their food...   \n",
       "3  when tables opened up, the manager sat another...   \n",
       "4  when tables opened up, the manager sat another...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [The, decor, is, not, special, at, all, but, t...   \n",
       "1  [The, decor, is, not, special, at, all, but, t...   \n",
       "2  [The, decor, is, not, special, at, all, but, t...   \n",
       "3  [when, tables, opened, up, ,, the, manager, sa...   \n",
       "4  [when, tables, opened, up, ,, the, manager, sa...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, ...  \n",
       "3            [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  \n",
       "4            [0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ABSA/MAMS/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/MAMS/models/bert_fine_tuned_dropout_cnn_bilstm_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/MAMS/stats/bert_fine_tuned_dropout_cnn_bilstm_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.337424874305725\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.06588121503591537\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.04964529350399971\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.046402085572481155\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.045496005564928055\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.03715670853853226\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.026098119094967842\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.04837885499000549\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.04134152829647064\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.03735505789518356\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.029250850901007652\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.02179548144340515\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.019059281796216965\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.03356434404850006\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.023434842005372047\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.016522405669093132\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.027374884113669395\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.020623428747057915\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.028609981760382652\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.027691883966326714\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.0176168791949749\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.01598992571234703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3903459310531616\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.05805936083197594\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.04446237161755562\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.035281069576740265\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.030495591461658478\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.02675103023648262\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.030400747433304787\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.024205323308706284\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.03527204692363739\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.024949975311756134\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.02465018257498741\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.047750718891620636\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.01827072724699974\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.022552605718374252\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.027882158756256104\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.027007728815078735\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.021534988656640053\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.0147434426471591\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.02099325880408287\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.02468949556350708\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.021239932626485825\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.021872928366065025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.4443761110305786\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.07694996893405914\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.0510706827044487\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.04272520914673805\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.03513428568840027\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.04658816382288933\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.05464542284607887\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.04031216353178024\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.028560126200318336\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.06860407441854477\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.02433713525533676\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.033887751400470734\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.039969105273485184\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.02108311839401722\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.030116135254502296\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.036938607692718506\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.02099326252937317\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.03064536862075329\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.024447796866297722\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.01819649524986744\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.026109939441084862\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.021404564380645752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3898239135742188\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.057664304971694946\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.0434998981654644\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.03203262388706207\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.06295375525951385\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.024290993809700012\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.03382594510912895\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.030079802498221397\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.04680955410003662\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.02906038984656334\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.032683663070201874\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.019945180043578148\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.029746176674962044\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.03460461646318436\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.015263566747307777\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.034105055034160614\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.02013171836733818\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.016732679679989815\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.018233945593237877\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.022824471816420555\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.029154818505048752\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.023154614493250847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.368764042854309\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.10554052889347076\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.10064486414194107\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.0597253255546093\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.04104592651128769\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.044972144067287445\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.04261232167482376\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.041253041476011276\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.036957018077373505\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.024608302861452103\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.029533429071307182\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.03254769742488861\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.028459109365940094\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.030201751738786697\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.028992995619773865\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.017882371321320534\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.024692241102457047\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.0378577783703804\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.029695812612771988\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.02099931798875332\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.016931472346186638\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.016987893730401993\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3189647197723389\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.10330171883106232\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.05915118381381035\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.060571517795324326\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.03866175189614296\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.06277237832546234\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.04051000252366066\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.03456757590174675\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.03691595047712326\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.036064811050891876\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.02226567082107067\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.037120137363672256\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.027950869873166084\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.04088475555181503\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.02756224200129509\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.02458035945892334\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.020286904647946358\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.022674908861517906\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.04727623239159584\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.02369176223874092\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.022097714245319366\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.029975442215800285\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3517872095108032\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.13050104677677155\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.07268226146697998\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.06326020509004593\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.04652555659413338\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.02904243767261505\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.024818630889058113\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.033971868455410004\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.03975952789187431\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.04208812117576599\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.03369344770908356\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.044954825192689896\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.02690243534743786\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.02865816466510296\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.0335816890001297\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.024870991706848145\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.024751050397753716\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.02168087102472782\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.017433185130357742\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.028132418170571327\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.022616764530539513\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.015269472263753414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3674522638320923\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.06595898419618607\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.06338416039943695\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.042411599308252335\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.03782764822244644\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.03883666172623634\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.022984547540545464\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.03253750503063202\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.03576252982020378\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.020682288333773613\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.03230959177017212\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.036385778337717056\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.030680935829877853\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.024990489706397057\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.022984640672802925\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.015107674524188042\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.03476819023489952\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.01251899916678667\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.028437072411179543\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.03185046464204788\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.022409163415431976\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.03116479702293873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3470470905303955\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.06796323508024216\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.04075315222144127\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.04358958825469017\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.03260678052902222\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.030927062034606934\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.04044903814792633\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.0471179224550724\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.035143181681632996\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.059345196932554245\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.03294423595070839\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.020972566679120064\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.012971581891179085\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.02714782953262329\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.02948751114308834\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.025712875649333\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.01853383705019951\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.020308036357164383\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.019838467240333557\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.01825215294957161\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.024984559044241905\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.02143973857164383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/2237, Loss: 1.3848083019256592\n",
      "Epoch: 0/2, Batch: 223/2237, Loss: 0.06975953280925751\n",
      "Epoch: 0/2, Batch: 446/2237, Loss: 0.03455674275755882\n",
      "Epoch: 0/2, Batch: 669/2237, Loss: 0.044937100261449814\n",
      "Epoch: 0/2, Batch: 892/2237, Loss: 0.046358175575733185\n",
      "Epoch: 0/2, Batch: 1115/2237, Loss: 0.03617854416370392\n",
      "Epoch: 0/2, Batch: 1338/2237, Loss: 0.02188854292035103\n",
      "Epoch: 0/2, Batch: 1561/2237, Loss: 0.04947226867079735\n",
      "Epoch: 0/2, Batch: 1784/2237, Loss: 0.022064607590436935\n",
      "Epoch: 0/2, Batch: 2007/2237, Loss: 0.04551277309656143\n",
      "Epoch: 0/2, Batch: 2230/2237, Loss: 0.03140935301780701\n",
      "Epoch: 1/2, Batch: 0/2237, Loss: 0.02447187528014183\n",
      "Epoch: 1/2, Batch: 223/2237, Loss: 0.02643175609409809\n",
      "Epoch: 1/2, Batch: 446/2237, Loss: 0.02746272087097168\n",
      "Epoch: 1/2, Batch: 669/2237, Loss: 0.023923154920339584\n",
      "Epoch: 1/2, Batch: 892/2237, Loss: 0.028636373579502106\n",
      "Epoch: 1/2, Batch: 1115/2237, Loss: 0.02193189226090908\n",
      "Epoch: 1/2, Batch: 1338/2237, Loss: 0.019934164360165596\n",
      "Epoch: 1/2, Batch: 1561/2237, Loss: 0.013590934686362743\n",
      "Epoch: 1/2, Batch: 1784/2237, Loss: 0.014700988307595253\n",
      "Epoch: 1/2, Batch: 2007/2237, Loss: 0.03978750482201576\n",
      "Epoch: 1/2, Batch: 2230/2237, Loss: 0.0171509962528944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_CNN_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.446461</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.428879</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.426070</td>\n",
       "      <td>1682.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.992493</td>\n",
       "      <td>0.992493</td>\n",
       "      <td>0.456860</td>\n",
       "      <td>0.992493</td>\n",
       "      <td>0.429427</td>\n",
       "      <td>0.992493</td>\n",
       "      <td>0.435601</td>\n",
       "      <td>1587.316220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.435759</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.426446</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.423515</td>\n",
       "      <td>1586.886021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992632</td>\n",
       "      <td>0.992632</td>\n",
       "      <td>0.454012</td>\n",
       "      <td>0.992632</td>\n",
       "      <td>0.455001</td>\n",
       "      <td>0.992632</td>\n",
       "      <td>0.442801</td>\n",
       "      <td>1589.593208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991207</td>\n",
       "      <td>0.991207</td>\n",
       "      <td>0.406379</td>\n",
       "      <td>0.991207</td>\n",
       "      <td>0.300430</td>\n",
       "      <td>0.991207</td>\n",
       "      <td>0.317384</td>\n",
       "      <td>1590.068523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.465261</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.312875</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>0.346455</td>\n",
       "      <td>1588.665030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.992092</td>\n",
       "      <td>0.992092</td>\n",
       "      <td>0.462284</td>\n",
       "      <td>0.992092</td>\n",
       "      <td>0.419814</td>\n",
       "      <td>0.992092</td>\n",
       "      <td>0.435875</td>\n",
       "      <td>1589.307721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.462541</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.426954</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.438015</td>\n",
       "      <td>1589.917121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.992090</td>\n",
       "      <td>0.992090</td>\n",
       "      <td>0.432031</td>\n",
       "      <td>0.992090</td>\n",
       "      <td>0.436874</td>\n",
       "      <td>0.992090</td>\n",
       "      <td>0.411031</td>\n",
       "      <td>1588.980866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.447269</td>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.450963</td>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.442479</td>\n",
       "      <td>1588.134304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.992356               0.992356               0.446461            0.992356   \n",
       "1  0.992493               0.992493               0.456860            0.992493   \n",
       "2  0.992098               0.992098               0.435759            0.992098   \n",
       "3  0.992632               0.992632               0.454012            0.992632   \n",
       "4  0.991207               0.991207               0.406379            0.991207   \n",
       "5  0.991474               0.991474               0.465261            0.991474   \n",
       "6  0.992092               0.992092               0.462284            0.992092   \n",
       "7  0.992484               0.992484               0.462541            0.992484   \n",
       "8  0.992090               0.992090               0.432031            0.992090   \n",
       "9  0.992455               0.992455               0.447269            0.992455   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.428879        0.992356        0.426070     1682.696700  \n",
       "1            0.429427        0.992493        0.435601     1587.316220  \n",
       "2            0.426446        0.992098        0.423515     1586.886021  \n",
       "3            0.455001        0.992632        0.442801     1589.593208  \n",
       "4            0.300430        0.991207        0.317384     1590.068523  \n",
       "5            0.312875        0.991474        0.346455     1588.665030  \n",
       "6            0.419814        0.992092        0.435875     1589.307721  \n",
       "7            0.426954        0.992484        0.438015     1589.917121  \n",
       "8            0.436874        0.992090        0.411031     1588.980866  \n",
       "9            0.450963        0.992455        0.442479     1588.134304  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
