{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_Linear import ABSA_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.6813029050827026\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.032318178564310074\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.023857953026890755\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.026729945093393326\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.011068263091146946\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.022189825773239136\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.019006170332431793\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03243911266326904\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.019130604341626167\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01511656865477562\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.009167409501969814\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01789938658475876\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02422196976840496\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.010774345137178898\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.012576853856444359\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.004896908067166805\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.006164856720715761\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01636437140405178\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.013013624586164951\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.009055382572114468\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.005670469719916582\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0052634491585195065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2682029008865356\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.028405262157320976\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.018584750592708588\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.02536383457481861\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.009203222580254078\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.016501735895872116\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.01723845861852169\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.013724899850785732\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.014708678238093853\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01828308403491974\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0071647511795163155\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01606978289783001\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.011026180349290371\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.013074729591608047\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009941943921148777\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.016430707648396492\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.006025110371410847\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.004438766278326511\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.017287110909819603\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.011498531326651573\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00520809181034565\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.014292336069047451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3954671621322632\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.09592089056968689\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.028878364711999893\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.04011870175600052\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03877433389425278\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03684636950492859\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03523527458310127\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02258038893342018\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.007161418441683054\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.019068334251642227\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.012949289754033089\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.011499855667352676\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.021116849035024643\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007814641110599041\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.026213373988866806\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01370814349502325\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.022534247487783432\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009343501180410385\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008335283026099205\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.00888743344694376\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.005353809334337711\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.008448867127299309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2569469213485718\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.032131027430295944\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.046879976987838745\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03187593072652817\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.021068025380373\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.026253102347254753\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.022961487993597984\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.01758885756134987\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01747012697160244\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.012726875953376293\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.009157135151326656\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020668094977736473\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.002260855631902814\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.012003902345895767\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.007295872084796429\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008307566866278648\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.007021808531135321\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.012275555171072483\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008775505237281322\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.016429245471954346\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.011244012042880058\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011807642877101898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.5094325542449951\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.031463343650102615\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03911306709051132\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.022827405482530594\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.015931246802210808\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.020933765918016434\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02470638044178486\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022050751373171806\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.024113798514008522\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02685347944498062\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.027108479291200638\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.011015110649168491\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022003790363669395\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.013444889336824417\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.006591042038053274\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.016183435916900635\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.009096801280975342\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.003688811557367444\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008967879228293896\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.016638856381177902\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.016141828149557114\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009951462969183922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.299161434173584\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.04009971767663956\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.020477544516324997\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.019648486748337746\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04379485175013542\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.022170662879943848\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.024556243792176247\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.014522699639201164\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.019363118335604668\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.026292411610484123\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.018942223861813545\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.010949503630399704\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.00693416316062212\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01625581458210945\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.014184142462909222\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01174414437264204\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.004543240647763014\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.00782205630093813\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.007426642347127199\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01738840714097023\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009154885075986385\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.012247573584318161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2822318077087402\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.036463093012571335\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.01178500335663557\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.020620064809918404\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.021850354969501495\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05025884509086609\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.020569678395986557\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.024301942437887192\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01698419079184532\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023917676880955696\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02313634566962719\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.011094370856881142\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.01162947528064251\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.010127865709364414\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009340859949588776\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010856571607291698\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01802600733935833\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.00498782517388463\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00509561225771904\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.013351536355912685\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.015345294959843159\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016395125538110733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2616565227508545\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.03530380129814148\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03448747843503952\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.030288947746157646\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.039842959493398666\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.026450108736753464\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.024494631215929985\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.01896977610886097\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.011994728818535805\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.020403483882546425\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0036394274793565273\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02912362664937973\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.008268716745078564\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.008020010776817799\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.007181885186582804\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.013349470682442188\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.024552112445235252\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.004945945926010609\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.013211549259722233\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.005868774373084307\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009514757432043552\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0036529775243252516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.401513934135437\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.03550565987825394\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03808692842721939\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.011559308506548405\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.037529561668634415\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.027028538286685944\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.013810166157782078\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.017548993229866028\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.024630781263113022\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.012560867704451084\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.012194148264825344\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014036959037184715\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.008247597143054008\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007078836672008038\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.013338840566575527\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.012130413204431534\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008928400464355946\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.006748026702553034\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012746061198413372\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0036505921743810177\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.005789932794868946\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009051068685948849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.522618055343628\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0243550855666399\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04350343719124794\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.02152916043996811\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.023712893947958946\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.029804641380906105\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.034557946026325226\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.035111717879772186\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02310279756784439\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.010644391179084778\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.013952825218439102\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.013465547002851963\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.017365435138344765\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.009584645740687847\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.012984356842935085\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.013406788930296898\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.021128738299012184\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0054162899032235146\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01319244783371687\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.005091664381325245\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0028747052419930696\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.004256784450262785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_Linear(BertModel.from_pretrained('bert-base-uncased'), dropout=0.3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "    \n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ABSA/SemEval16 - Task 5 - Restaurants/plots/bert_pt_do_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.bert, BERT_FINE_TUNED_OUTPUT)\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.400640</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.450754</td>\n",
       "      <td>0.996875</td>\n",
       "      <td>0.422131</td>\n",
       "      <td>331.585561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.466177</td>\n",
       "      <td>0.997449</td>\n",
       "      <td>0.432167</td>\n",
       "      <td>329.424239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997289</td>\n",
       "      <td>0.997289</td>\n",
       "      <td>0.410107</td>\n",
       "      <td>0.997289</td>\n",
       "      <td>0.463625</td>\n",
       "      <td>0.997289</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>330.981003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.608813</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.479246</td>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.455660</td>\n",
       "      <td>330.131548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.400973</td>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.467495</td>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.428216</td>\n",
       "      <td>330.963369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.997523</td>\n",
       "      <td>0.997523</td>\n",
       "      <td>0.423359</td>\n",
       "      <td>0.997523</td>\n",
       "      <td>0.448171</td>\n",
       "      <td>0.997523</td>\n",
       "      <td>0.434948</td>\n",
       "      <td>361.233716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.415364</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.472753</td>\n",
       "      <td>0.997371</td>\n",
       "      <td>0.439804</td>\n",
       "      <td>356.150496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.405068</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.444003</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.422382</td>\n",
       "      <td>347.421640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.408809</td>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.463880</td>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.432274</td>\n",
       "      <td>342.439443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997195</td>\n",
       "      <td>0.997195</td>\n",
       "      <td>0.398292</td>\n",
       "      <td>0.997195</td>\n",
       "      <td>0.474628</td>\n",
       "      <td>0.997195</td>\n",
       "      <td>0.428631</td>\n",
       "      <td>339.185600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.996875               0.996875               0.400640            0.996875   \n",
       "1  0.997449               0.997449               0.407401            0.997449   \n",
       "2  0.997289               0.997289               0.410107            0.997289   \n",
       "3  0.997453               0.997453               0.608813            0.997453   \n",
       "4  0.997223               0.997223               0.400973            0.997223   \n",
       "5  0.997523               0.997523               0.423359            0.997523   \n",
       "6  0.997371               0.997371               0.415364            0.997371   \n",
       "7  0.997117               0.997117               0.405068            0.997117   \n",
       "8  0.997426               0.997426               0.408809            0.997426   \n",
       "9  0.997195               0.997195               0.398292            0.997195   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.450754        0.996875        0.422131      331.585561  \n",
       "1            0.466177        0.997449        0.432167      329.424239  \n",
       "2            0.463625        0.997289        0.433034      330.981003  \n",
       "3            0.479246        0.997453        0.455660      330.131548  \n",
       "4            0.467495        0.997223        0.428216      330.963369  \n",
       "5            0.448171        0.997523        0.434948      361.233716  \n",
       "6            0.472753        0.997371        0.439804      356.150496  \n",
       "7            0.444003        0.997117        0.422382      347.421640  \n",
       "8            0.463880        0.997426        0.432274      342.439443  \n",
       "9            0.474628        0.997195        0.428631      339.185600  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
