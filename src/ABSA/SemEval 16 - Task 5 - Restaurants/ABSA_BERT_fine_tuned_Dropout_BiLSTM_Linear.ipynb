{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_BiLSTM_Linear import ABSA_BERT_Dropout_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_bilstm_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_bilstm_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4245624542236328\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.3275899887084961\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15733234584331512\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.1870076060295105\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.14329196512699127\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.14260898530483246\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06159212067723274\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.12087592482566833\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.1780386120080948\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.14162801206111908\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0847201943397522\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.08411674201488495\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.05335589125752449\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.07639379054307938\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.06630731374025345\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.11510130763053894\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.1399868279695511\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.10587586462497711\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05517914891242981\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.040301818400621414\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.06653164327144623\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.036396387964487076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4087523221969604\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.3260759115219116\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.11777027696371078\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.13564379513263702\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.23264552652835846\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.13371409475803375\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.11931739002466202\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.11925467848777771\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.06234820932149887\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.17038434743881226\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.09486900269985199\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.2564319670200348\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0758480355143547\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03141826018691063\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03875114023685455\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.10888990759849548\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.03600764647126198\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.042213860899209976\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.07276428490877151\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03545919805765152\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.04641256481409073\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.08894350379705429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.5532532930374146\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4134198725223541\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.21246513724327087\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0608782060444355\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.2729940116405487\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.1138898953795433\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.14737197756767273\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.18809998035430908\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.08037018030881882\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.06574970483779907\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.12902379035949707\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.06655297428369522\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.12400758266448975\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.1167212501168251\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.09341291338205338\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.07993372529745102\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04226921126246452\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.010010933503508568\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.023392992094159126\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.04787246137857437\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.05474686622619629\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.03214764595031738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.409014344215393\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.24830706417560577\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.12141089141368866\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07557900249958038\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07873042672872543\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.12064461410045624\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.14649491012096405\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.08445066213607788\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.08589819073677063\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0417717844247818\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.039152175188064575\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0940987765789032\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.07748017460107803\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.08169230818748474\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.07441793382167816\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.19267907738685608\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04281178116798401\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.017467912286520004\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0559372678399086\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03064691089093685\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.06684321910142899\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.039550360292196274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4663223028182983\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.22806057333946228\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20729030668735504\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.062301162630319595\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.08742012083530426\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.15545684099197388\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.08483891189098358\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.10462570190429688\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.2338627129793167\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0570855587720871\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.07829227298498154\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.10877411812543869\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022782331332564354\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.09851391613483429\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02591826394200325\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.144511878490448\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.13111107051372528\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03535860776901245\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05994578078389168\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.08349122852087021\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.040555499494075775\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.034021664410829544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3462337255477905\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.2457381784915924\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1516442447900772\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.2412780523300171\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.17038990557193756\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.10128539800643921\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.07529512792825699\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.10419352352619171\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04638389125466347\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.08363622426986694\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.06906113773584366\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.09525179117918015\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.10138456523418427\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.18918710947036743\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.04944639652967453\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.17783887684345245\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.031327683478593826\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.07311133295297623\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.08513703942298889\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.034442633390426636\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.09123748540878296\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.11537790298461914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4459108114242554\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.2680813670158386\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.23732468485832214\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.1251402050256729\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.15939539670944214\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.06731002777814865\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.1022816002368927\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.07026776671409607\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.10347913950681686\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.11128056049346924\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.06708217412233353\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03401647135615349\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04605994373559952\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.023361526429653168\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.06306792795658112\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.06827759742736816\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.05271604657173157\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.15760502219200134\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03610401228070259\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.022826772183179855\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.055219996720552444\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0722694918513298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4169495105743408\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.16586537659168243\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1573215276002884\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.11487412452697754\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.09652207791805267\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.08598217368125916\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.1306619793176651\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.07882948964834213\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.08517010509967804\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.07384881377220154\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.09921663254499435\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.15032508969306946\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.044735949486494064\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.028276806697249413\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.07866131514310837\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.039248276501894\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.05845477804541588\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03686130791902542\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.07532984763383865\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.06692701578140259\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.046842895448207855\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.07735130935907364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3969430923461914\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.29511919617652893\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16974599659442902\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07268745452165604\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.10692350566387177\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.13919739425182343\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.14729122817516327\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.15302777290344238\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04983145371079445\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0906340628862381\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.08666247129440308\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.07242336124181747\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.020649464800953865\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.021694522351026535\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.030912764370441437\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.05036359280347824\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.09514054656028748\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.10801661759614944\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02815849520266056\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.04056895896792412\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.04168235883116722\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0984513983130455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4566614627838135\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.24486267566680908\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15688090026378632\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.21815237402915955\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.10492637008428574\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.09181434661149979\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06927237659692764\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.05551331862807274\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.07030792534351349\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.2451610118150711\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.17908231914043427\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.06461773812770844\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.06869976222515106\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.06355331838130951\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0119858393445611\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02232171781361103\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.05062120780348778\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.04179224371910095\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05506560951471329\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.10277734696865082\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.032019153237342834\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.10159675031900406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), dropout=0.3, bilstm_in_features=256, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985860</td>\n",
       "      <td>0.985860</td>\n",
       "      <td>0.680909</td>\n",
       "      <td>0.985860</td>\n",
       "      <td>0.688010</td>\n",
       "      <td>0.985860</td>\n",
       "      <td>0.683279</td>\n",
       "      <td>129.921999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.611569</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.694209</td>\n",
       "      <td>0.978756</td>\n",
       "      <td>0.646792</td>\n",
       "      <td>117.928999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.673924</td>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.694054</td>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.683737</td>\n",
       "      <td>117.782001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986065</td>\n",
       "      <td>0.986065</td>\n",
       "      <td>0.676308</td>\n",
       "      <td>0.986065</td>\n",
       "      <td>0.676815</td>\n",
       "      <td>0.986065</td>\n",
       "      <td>0.676465</td>\n",
       "      <td>116.665001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.660187</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.698459</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.677305</td>\n",
       "      <td>117.215999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.984499</td>\n",
       "      <td>0.984499</td>\n",
       "      <td>0.659566</td>\n",
       "      <td>0.984499</td>\n",
       "      <td>0.685239</td>\n",
       "      <td>0.984499</td>\n",
       "      <td>0.671911</td>\n",
       "      <td>117.351001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.661383</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.713460</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.685443</td>\n",
       "      <td>117.412999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.986366</td>\n",
       "      <td>0.986366</td>\n",
       "      <td>0.682138</td>\n",
       "      <td>0.986366</td>\n",
       "      <td>0.702056</td>\n",
       "      <td>0.986366</td>\n",
       "      <td>0.691748</td>\n",
       "      <td>116.962996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981915</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>0.642603</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>0.693438</td>\n",
       "      <td>0.981915</td>\n",
       "      <td>0.666296</td>\n",
       "      <td>117.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.615907</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.708705</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.654890</td>\n",
       "      <td>117.081000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.985860               0.985860               0.680909            0.985860   \n",
       "1  0.978756               0.978756               0.611569            0.978756   \n",
       "2  0.984760               0.984760               0.673924            0.984760   \n",
       "3  0.986065               0.986065               0.676308            0.986065   \n",
       "4  0.986077               0.986077               0.660187            0.986077   \n",
       "5  0.984499               0.984499               0.659566            0.984499   \n",
       "6  0.982896               0.982896               0.661383            0.982896   \n",
       "7  0.986366               0.986366               0.682138            0.986366   \n",
       "8  0.981915               0.981915               0.642603            0.981915   \n",
       "9  0.979707               0.979707               0.615907            0.979707   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.688010        0.985860        0.683279      129.921999  \n",
       "1            0.694209        0.978756        0.646792      117.928999  \n",
       "2            0.694054        0.984760        0.683737      117.782001  \n",
       "3            0.676815        0.986065        0.676465      116.665001  \n",
       "4            0.698459        0.986077        0.677305      117.215999  \n",
       "5            0.685239        0.984499        0.671911      117.351001  \n",
       "6            0.713460        0.982896        0.685443      117.412999  \n",
       "7            0.702056        0.986366        0.691748      116.962996  \n",
       "8            0.693438        0.981915        0.666296      117.267000  \n",
       "9            0.708705        0.979707        0.654890      117.081000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
