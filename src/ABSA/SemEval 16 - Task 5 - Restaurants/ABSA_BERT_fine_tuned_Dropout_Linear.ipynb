{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_Linear import ABSA_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2192856073379517\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.14524944126605988\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.07134665548801422\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.022834982722997665\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03208481892943382\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.11824347078800201\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0375695563852787\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.06119386479258537\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0995965525507927\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.037751272320747375\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.034646376967430115\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.027884313836693764\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.017969103530049324\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0761646255850792\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0815887600183487\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01859542541205883\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.044734127819538116\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.04084711894392967\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.011489998549222946\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.014954568818211555\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.020836390554904938\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.05690481886267662\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.5904805660247803\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.08733458071947098\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.08698148280382156\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.019658077508211136\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05132163316011429\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0475015752017498\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.12271679937839508\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.046757910400629044\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.006229479797184467\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.10392758250236511\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.09754670411348343\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.007625469472259283\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.027820061892271042\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.020905766636133194\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.010066619142889977\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.017710398882627487\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015266587026417255\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.022149669006466866\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03290772810578346\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025403812527656555\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0592130646109581\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.03229733929038048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.349490761756897\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.07041408866643906\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03137765824794769\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.1312115341424942\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0369698703289032\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04585210606455803\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.014551891945302486\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.015732765197753906\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0055825901217758656\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.07993457466363907\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.07829033583402634\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014512639492750168\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.06725473701953888\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.06459648907184601\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.030837060883641243\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.05601300299167633\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04259899631142616\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01589256525039673\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03622356057167053\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.026489339768886566\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.02526330202817917\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.06669345498085022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.371902346611023\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.07042928040027618\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.09496767073869705\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08275280147790909\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.08349484205245972\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.011116023175418377\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0663209855556488\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.04129355400800705\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05127806216478348\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.1577591598033905\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.042101629078388214\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04772809520363808\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.031473610550165176\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.07644002884626389\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.04348011314868927\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04835059866309166\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04368799924850464\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02715257555246353\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0435798242688179\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.012772911228239536\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.15679602324962616\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.026357602328062057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3295319080352783\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.03148853778839111\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.09085922688245773\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07800865918397903\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.042824629694223404\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.048986587673425674\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04246745631098747\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.11031121760606766\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.10655477643013\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04407835006713867\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.021373648196458817\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.029239878058433533\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03691225126385689\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.012606032192707062\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.024339891970157623\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.10054315626621246\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008461270481348038\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02229062281548977\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.022923734039068222\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02477804385125637\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.12024624645709991\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01297870371490717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3917652368545532\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.14666056632995605\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.3779398202896118\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09269756078720093\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0840015858411789\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.2264525294303894\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.07303115725517273\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02259303815662861\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03601498529314995\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04114999994635582\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.06529584527015686\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.024579845368862152\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.07129933685064316\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.05062153935432434\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.025184225291013718\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.027115756645798683\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.08201992511749268\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.007353530265390873\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.018597664311528206\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006580540910363197\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.1160857304930687\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.10386500507593155\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3437018394470215\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.10406707227230072\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.09445368498563766\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.04741459712386131\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03243491053581238\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.058227647095918655\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.08066578954458237\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.21314741671085358\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.23770450055599213\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023104457184672356\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.11617133021354675\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04143067076802254\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.11247393488883972\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03608516976237297\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.06773053109645844\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02716577611863613\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.013226638548076153\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.001953202299773693\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.1319522112607956\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03075319156050682\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.03159531578421593\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.017631174996495247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.529990792274475\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.04068974778056145\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1398448497056961\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.17523221671581268\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.02684064954519272\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.010592305101454258\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.11210278421640396\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.018953820690512657\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.025227978825569153\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03870471194386482\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.13883239030838013\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03762127831578255\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.017697904258966446\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.04259184002876282\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009015156887471676\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.014062333852052689\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.10408025234937668\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.05302978679537773\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05192335322499275\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.039314717054367065\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.019541582092642784\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.058315325528383255\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.6659377813339233\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.1528729945421219\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0912209302186966\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.04005351662635803\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.12176799774169922\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.16489063203334808\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.044114258140325546\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0908271074295044\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.025425825268030167\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.034513477236032486\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.11848516017198563\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.008376093581318855\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04798648878931999\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.010102377273142338\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.020655829459428787\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010449559427797794\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.03447829931974411\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.059316638857126236\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.04905819147825241\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02601579762995243\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.014259283430874348\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.04391830042004585\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.960313320159912\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.1457289308309555\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0728813111782074\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.04661230370402336\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.038055676966905594\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.08821989595890045\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.08895906805992126\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.060217518359422684\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.07519054412841797\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.14493779838085175\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.06954429298639297\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.05234700068831444\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03622071072459221\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01214447058737278\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.012684473767876625\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.058236509561538696\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.13493826985359192\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.16277335584163666\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019557097926735878\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025418246164917946\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.019630983471870422\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.010498588904738426\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_Linear(torch.load(BERT_FINE_TUNED_PATH), dropout=0.3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.983592</td>\n",
       "      <td>0.983592</td>\n",
       "      <td>0.914755</td>\n",
       "      <td>0.983592</td>\n",
       "      <td>0.719106</td>\n",
       "      <td>0.983592</td>\n",
       "      <td>0.719788</td>\n",
       "      <td>111.428999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.665687</td>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.686409</td>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.674743</td>\n",
       "      <td>105.950998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.688113</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.713356</td>\n",
       "      <td>0.988978</td>\n",
       "      <td>0.700026</td>\n",
       "      <td>112.231005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.986627</td>\n",
       "      <td>0.986627</td>\n",
       "      <td>0.663254</td>\n",
       "      <td>0.986627</td>\n",
       "      <td>0.714438</td>\n",
       "      <td>0.986627</td>\n",
       "      <td>0.684872</td>\n",
       "      <td>110.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.987628</td>\n",
       "      <td>0.987628</td>\n",
       "      <td>0.687074</td>\n",
       "      <td>0.987628</td>\n",
       "      <td>0.712026</td>\n",
       "      <td>0.987628</td>\n",
       "      <td>0.699044</td>\n",
       "      <td>109.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.744869</td>\n",
       "      <td>0.985831</td>\n",
       "      <td>0.752467</td>\n",
       "      <td>111.006002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.985644</td>\n",
       "      <td>0.985644</td>\n",
       "      <td>0.677406</td>\n",
       "      <td>0.985644</td>\n",
       "      <td>0.707978</td>\n",
       "      <td>0.985644</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>111.963002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984780</td>\n",
       "      <td>0.984780</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>0.984780</td>\n",
       "      <td>0.698788</td>\n",
       "      <td>0.984780</td>\n",
       "      <td>0.717338</td>\n",
       "      <td>109.810998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.933443</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.692413</td>\n",
       "      <td>0.982809</td>\n",
       "      <td>0.721876</td>\n",
       "      <td>109.367999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.984983</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>0.937207</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>0.729587</td>\n",
       "      <td>0.984983</td>\n",
       "      <td>0.757635</td>\n",
       "      <td>110.550999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.983592               0.983592               0.914755            0.983592   \n",
       "1  0.982829               0.982829               0.665687            0.982829   \n",
       "2  0.988978               0.988978               0.688113            0.988978   \n",
       "3  0.986627               0.986627               0.663254            0.986627   \n",
       "4  0.987628               0.987628               0.687074            0.987628   \n",
       "5  0.985831               0.985831               0.920792            0.985831   \n",
       "6  0.985644               0.985644               0.677406            0.985644   \n",
       "7  0.984780               0.984780               0.925881            0.984780   \n",
       "8  0.982809               0.982809               0.933443            0.982809   \n",
       "9  0.984983               0.984983               0.937207            0.984983   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.719106        0.983592        0.719788      111.428999  \n",
       "1            0.686409        0.982829        0.674743      105.950998  \n",
       "2            0.713356        0.988978        0.700026      112.231005  \n",
       "3            0.714438        0.986627        0.684872      110.252000  \n",
       "4            0.712026        0.987628        0.699044      109.548000  \n",
       "5            0.744869        0.985831        0.752467      111.006002  \n",
       "6            0.707978        0.985644        0.691803      111.963002  \n",
       "7            0.698788        0.984780        0.717338      109.810998  \n",
       "8            0.692413        0.982809        0.721876      109.367999  \n",
       "9            0.729587        0.984983        0.757635      110.550999  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
