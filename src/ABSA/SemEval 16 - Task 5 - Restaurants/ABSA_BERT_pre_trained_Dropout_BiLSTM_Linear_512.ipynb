{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_BiLSTM_Linear import ABSA_BERT_Dropout_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_bilstm_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_bilstm_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4025187492370605\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.10126699507236481\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.06132068112492561\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.029395051300525665\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03187216818332672\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.024892928078770638\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.038860172033309937\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.04153978079557419\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.013941685669124126\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0318756103515625\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.04233609139919281\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02751404047012329\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04281157627701759\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.055029042065143585\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01889128051698208\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02391939051449299\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008717386983335018\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02943866327404976\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.022413332015275955\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.021752063184976578\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.015043912455439568\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015617378056049347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4605388641357422\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.08135326206684113\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04323241859674454\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09497629106044769\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.02573077753186226\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.043287668377161026\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.021370459347963333\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.040406323969364166\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04029173403978348\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03747021406888962\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02020321413874626\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.029203880578279495\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.01524862740188837\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.020290762186050415\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.028817541897296906\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01861860230565071\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01780988648533821\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03305967152118683\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.013903598301112652\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03231286257505417\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.02024408057332039\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.013853590935468674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4292340278625488\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.09900355339050293\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.07043051719665527\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03402223810553551\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0355326309800148\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.06955531984567642\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.023589838296175003\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.026523659005761147\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.049054984003305435\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02147614397108555\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.039840877056121826\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03097626008093357\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03717758134007454\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0527292862534523\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0469573475420475\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01962929032742977\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.012425223365426064\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02046097442507744\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.023662034422159195\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025422047823667526\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01402121502906084\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02161233499646187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.392066240310669\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.10530321300029755\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.05553359538316727\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.05441371351480484\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05280465632677078\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.09013396501541138\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05353311449289322\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.024499436840415\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04754072055220604\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03294844180345535\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03262968361377716\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.026483165100216866\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04432077333331108\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03768971562385559\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.008562938310205936\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.020949164405465126\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.024654291570186615\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.015848379582166672\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.010432587936520576\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.018828008323907852\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.014094393700361252\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016739074140787125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4399784803390503\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.12313874065876007\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.049920324236154556\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0372442789375782\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07893357425928116\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05031620338559151\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03940710052847862\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.08582378923892975\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.036745455116033554\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.022690998390316963\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.020590348169207573\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.018752656877040863\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022152762860059738\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.018248435109853745\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.028957471251487732\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.019717497751116753\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015332183800637722\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.018676552921533585\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.021529676392674446\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.020949535071849823\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009148827753961086\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.008932099677622318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2068442106246948\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.08341449499130249\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.08662234246730804\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03552434593439102\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.020333176478743553\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03667275980114937\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05520514398813248\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.020946785807609558\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.042505983263254166\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.025283655151724815\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03987567499279976\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.022058384492993355\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02174915000796318\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.020736292004585266\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.011474093422293663\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.016085805371403694\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02326231263577938\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.011972956359386444\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.015180126763880253\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01830068603157997\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.022993309423327446\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.020730620250105858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.5186386108398438\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.11491479724645615\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.05848198011517525\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03511391207575798\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04425337165594101\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02898811548948288\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.028824565932154655\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03376530483365059\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.028187457472085953\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023137686774134636\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.035039905458688736\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.015606309287250042\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03313305228948593\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.015894586220383644\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.018032588064670563\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.013552245683968067\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.011769241653382778\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01776159182190895\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012663619592785835\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01800798997282982\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01894637756049633\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015190447680652142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3873039484024048\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.11550785601139069\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.05386434867978096\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.04234788566827774\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.055763304233551025\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04086562246084213\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.021267013624310493\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.025467514991760254\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.041799504309892654\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02590803988277912\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.030977455899119377\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.036239489912986755\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022370917722582817\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02532777562737465\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.030459506437182426\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.03272786736488342\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015459025278687477\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.013189702294766903\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.014036089181900024\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0096821840852499\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010687113739550114\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01467097643762827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4554989337921143\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.12241309136152267\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.049696680158376694\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03871793672442436\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04210398346185684\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.017495712265372276\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04496234282851219\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.04759301245212555\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.034088630229234695\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04974916949868202\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.04187829792499542\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.029374226927757263\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.030309826135635376\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03221311420202255\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.016166601330041885\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.027664221823215485\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.011330223642289639\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.010523764416575432\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02472105249762535\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.013637230731546879\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006073156371712685\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011295892298221588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3432512283325195\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.08765968680381775\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.05349735543131828\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.051189932972192764\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.037613239139318466\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0331394337117672\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.025327198207378387\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022820213809609413\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01685369946062565\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.017974765971302986\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.022418437525629997\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.026703352108597755\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.024249127134680748\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01836538501083851\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.016584936529397964\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04079845920205116\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02032162994146347\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.008195714093744755\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.013223177753388882\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.016940515488386154\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00585215725004673\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02544250898063183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_BiLSTM_Linear(BertModel.from_pretrained('bert-base-uncased'), dropout=0.3, bilstm_in_features=256, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "    \n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ABSA/SemEval16 - Task 5 - Restaurants/plots/bert_pt_do_bilstm_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.403832</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.374396</td>\n",
       "      <td>0.996141</td>\n",
       "      <td>0.387514</td>\n",
       "      <td>375.954340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.453195</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.286984</td>\n",
       "      <td>0.995516</td>\n",
       "      <td>0.312106</td>\n",
       "      <td>371.122459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995480</td>\n",
       "      <td>0.995480</td>\n",
       "      <td>0.456639</td>\n",
       "      <td>0.995480</td>\n",
       "      <td>0.279457</td>\n",
       "      <td>0.995480</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>370.249193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995156</td>\n",
       "      <td>0.995156</td>\n",
       "      <td>0.452042</td>\n",
       "      <td>0.995156</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.995156</td>\n",
       "      <td>0.302923</td>\n",
       "      <td>369.659994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.428249</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.403716</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.415043</td>\n",
       "      <td>369.725528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.443893</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.298327</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.326931</td>\n",
       "      <td>370.989926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995930</td>\n",
       "      <td>0.995930</td>\n",
       "      <td>0.387220</td>\n",
       "      <td>0.995930</td>\n",
       "      <td>0.419665</td>\n",
       "      <td>0.995930</td>\n",
       "      <td>0.401744</td>\n",
       "      <td>370.260632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.411216</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.340618</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.365849</td>\n",
       "      <td>370.920694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.419668</td>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.368269</td>\n",
       "      <td>0.996168</td>\n",
       "      <td>0.389290</td>\n",
       "      <td>357.120473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.411273</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.350967</td>\n",
       "      <td>0.995859</td>\n",
       "      <td>0.374053</td>\n",
       "      <td>348.858617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.996141               0.996141               0.403832            0.996141   \n",
       "1  0.995516               0.995516               0.453195            0.995516   \n",
       "2  0.995480               0.995480               0.456639            0.995480   \n",
       "3  0.995156               0.995156               0.452042            0.995156   \n",
       "4  0.996609               0.996609               0.428249            0.996609   \n",
       "5  0.995363               0.995363               0.443893            0.995363   \n",
       "6  0.995930               0.995930               0.387220            0.995930   \n",
       "7  0.995875               0.995875               0.411216            0.995875   \n",
       "8  0.996168               0.996168               0.419668            0.996168   \n",
       "9  0.995859               0.995859               0.411273            0.995859   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.374396        0.996141        0.387514      375.954340  \n",
       "1            0.286984        0.995516        0.312106      371.122459  \n",
       "2            0.279457        0.995480        0.301057      370.249193  \n",
       "3            0.280801        0.995156        0.302923      369.659994  \n",
       "4            0.403716        0.996609        0.415043      369.725528  \n",
       "5            0.298327        0.995363        0.326931      370.989926  \n",
       "6            0.419665        0.995930        0.401744      370.260632  \n",
       "7            0.340618        0.995875        0.365849      370.920694  \n",
       "8            0.368269        0.996168        0.389290      357.120473  \n",
       "9            0.350967        0.995859        0.374053      348.858617  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
