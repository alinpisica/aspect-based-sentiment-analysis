{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_CNN_BiLSTM_Linear import ABSA_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_cnn_bilstm_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_cnn_bilstm_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4036377668380737\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.540870726108551\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16217836737632751\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07981859892606735\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06743031740188599\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04107315093278885\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05272245779633522\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.032707009464502335\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.028365883976221085\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02345585636794567\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.030286168679594994\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.041478853672742844\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.026294734328985214\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.04192529246211052\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.027593262493610382\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0329744890332222\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.07231808453798294\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019179590046405792\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012083432637155056\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.030681826174259186\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01808125339448452\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011250895448029041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4488288164138794\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7619216442108154\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.18864081799983978\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.10109364986419678\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04584861174225807\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04234478622674942\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03629087656736374\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.033240802586078644\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0241562332957983\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03447873890399933\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.031178640201687813\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03549794480204582\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.029184814542531967\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.024362297728657722\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.017196688801050186\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.019786739721894264\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02922510914504528\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.022457554936408997\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.017510252073407173\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.017706599086523056\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.017126336693763733\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.048190146684646606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4013900756835938\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6839701533317566\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1788434535264969\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07996433973312378\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07365486025810242\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05156903713941574\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.038105323910713196\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.09188424050807953\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.036511678248643875\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.029605833813548088\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.04514841362833977\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03930458426475525\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02343575470149517\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02988218516111374\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02104380913078785\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.014056169427931309\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.021474188193678856\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.030707253143191338\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05734618753194809\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.038425564765930176\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.016000838950276375\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0065133594907820225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.382036805152893\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5913069844245911\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16195645928382874\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07620935142040253\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.08852601796388626\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.055136919021606445\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.028356468304991722\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02698620781302452\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.021782800555229187\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.058559443801641464\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.016710197553038597\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02030763030052185\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0180356502532959\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02988598681986332\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01734462007880211\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.029860135167837143\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.017401419579982758\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03034132905304432\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019549565389752388\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01814310811460018\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.011010993272066116\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015217848122119904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.364332914352417\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7345212697982788\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.19045481085777283\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08851534128189087\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06021557375788689\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.048158302903175354\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02688535861670971\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.037010423839092255\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.026737473905086517\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03932204470038414\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.040357816964387894\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02409849502146244\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.027072040364146233\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02176056057214737\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.04089869186282158\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.022289860993623734\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.016971055418252945\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009521083906292915\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02165956422686577\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025829557329416275\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0156276673078537\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.019130900502204895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3274149894714355\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.9432847499847412\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.32599082589149475\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.16294144093990326\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.11593853682279587\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.08834235370159149\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.07812868058681488\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.05525656417012215\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04733024537563324\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.05774877592921257\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03918929398059845\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.05337182432413101\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04667101055383682\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03897679224610329\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.06700148433446884\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.045714378356933594\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02428125962615013\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0448639802634716\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03383312746882439\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.041431013494729996\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.024182775989174843\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02325950190424919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3804653882980347\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.8773015141487122\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.23428449034690857\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.10784190148115158\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07887015491724014\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04479691758751869\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.053950872272253036\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.031086958944797516\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04153341427445412\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0399797186255455\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.030528975650668144\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02201954647898674\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02040676213800907\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029074694961309433\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02667306549847126\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.028832845389842987\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.00990784727036953\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.039963655173778534\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03539758548140526\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02182932198047638\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.012226016260683537\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.012797938659787178\n",
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.438366413116455\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.8508992195129395\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.24939756095409393\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09916221350431442\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06303288787603378\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04830797761678696\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.031110865995287895\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02982548624277115\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03527861461043358\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03423592820763588\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.028753986582159996\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.05234180763363838\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03094406984746456\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0192745178937912\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02551262639462948\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01867978647351265\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.03127551078796387\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01363202091306448\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02768940106034279\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.008447128348052502\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.017023541033267975\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01071876659989357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3504616022109985\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6222052574157715\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16073337197303772\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07605111598968506\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03830961510539055\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.044893015176057816\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.050498880445957184\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.055002521723508835\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.035290997475385666\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.035957153886556625\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.021950624883174896\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014182142913341522\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02492327243089676\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.047729652374982834\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02689414471387863\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010870326310396194\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.03057052567601204\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.015139080584049225\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05284928157925606\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.022009944543242455\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.015095721930265427\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.013163413852453232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3807799816131592\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6890122294425964\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.2196011245250702\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09113752096891403\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05349485203623772\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03679719939827919\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04184240102767944\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.029359113425016403\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05561598762869835\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.036041900515556335\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02465047687292099\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.028066463768482208\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02810288406908512\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.018674777820706367\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.025459708645939827\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04705602303147316\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01863742433488369\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01275164820253849\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02349366806447506\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.023953966796398163\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.021932009607553482\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01414608396589756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_CNN_BiLSTM_Linear(BertModel.from_pretrained('bert-base-uncased'), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.462972</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.252889</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.255044</td>\n",
       "      <td>485.788638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.248784</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.249391</td>\n",
       "      <td>482.152219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.427284</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.251253</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.251842</td>\n",
       "      <td>482.395524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995191</td>\n",
       "      <td>0.995191</td>\n",
       "      <td>0.498801</td>\n",
       "      <td>0.995191</td>\n",
       "      <td>0.250555</td>\n",
       "      <td>0.995191</td>\n",
       "      <td>0.250506</td>\n",
       "      <td>483.724639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.248784</td>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995137</td>\n",
       "      <td>0.249391</td>\n",
       "      <td>482.391957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.248711</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>485.672433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.508809</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.267298</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.281769</td>\n",
       "      <td>480.104544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995277</td>\n",
       "      <td>0.995277</td>\n",
       "      <td>0.415488</td>\n",
       "      <td>0.995277</td>\n",
       "      <td>0.251098</td>\n",
       "      <td>0.995277</td>\n",
       "      <td>0.251594</td>\n",
       "      <td>485.306624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.498761</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.250495</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.250366</td>\n",
       "      <td>482.151927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.523880</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.254150</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>486.071825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.994711               0.994711               0.462972            0.994711   \n",
       "1  0.995094               0.995094               0.248784            0.995094   \n",
       "2  0.994844               0.994844               0.427284            0.994844   \n",
       "3  0.995191               0.995191               0.498801            0.995191   \n",
       "4  0.995137               0.995137               0.248784            0.995137   \n",
       "5  0.994844               0.994844               0.248711            0.994844   \n",
       "6  0.994926               0.994926               0.508809            0.994926   \n",
       "7  0.995277               0.995277               0.415488            0.995277   \n",
       "8  0.995004               0.995004               0.498761            0.995004   \n",
       "9  0.995379               0.995379               0.523880            0.995379   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.252889        0.994711        0.255044      485.788638  \n",
       "1            0.250000        0.995094        0.249391      482.152219  \n",
       "2            0.251253        0.994844        0.251842      482.395524  \n",
       "3            0.250555        0.995191        0.250506      483.724639  \n",
       "4            0.250000        0.995137        0.249391      482.391957  \n",
       "5            0.250000        0.994844        0.249354      485.672433  \n",
       "6            0.267298        0.994926        0.281769      480.104544  \n",
       "7            0.251098        0.995277        0.251594      485.306624  \n",
       "8            0.250495        0.995004        0.250366      482.151927  \n",
       "9            0.254150        0.995379        0.256702      486.071825  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
