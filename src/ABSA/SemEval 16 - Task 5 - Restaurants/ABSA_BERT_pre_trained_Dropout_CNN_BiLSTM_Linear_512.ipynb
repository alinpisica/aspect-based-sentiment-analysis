{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_CNN_BiLSTM_Linear import ABSA_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_cnn_bilstm_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_cnn_bilstm_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4244142770767212\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7621605396270752\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16898216307163239\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07719364762306213\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.052880626171827316\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05863593518733978\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04053518921136856\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.053899310529232025\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02590976655483246\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.033876173198223114\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03617732599377632\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020049378275871277\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.031808916479349136\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.037650253623723984\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02042081020772457\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.023631004616618156\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02649899572134018\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009462804533541203\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.014706764370203018\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02211630530655384\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.019214261323213577\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015863794833421707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3823485374450684\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7779449224472046\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20638726651668549\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.11184384673833847\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.054087940603494644\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.056266989558935165\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05231497064232826\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03632121533155441\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03279614448547363\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03905732184648514\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02300729788839817\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.017945103347301483\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02195914275944233\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.04766159504652023\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.025572732090950012\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02589157596230507\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.031018631532788277\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.023107057437300682\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.020697321742773056\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.024786457419395447\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01946520246565342\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016543684527277946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4022974967956543\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5822946429252625\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.18358011543750763\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08579973876476288\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05762350931763649\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05097316950559616\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06596489995718002\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03518326207995415\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04147946089506149\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04013121873140335\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.023095794022083282\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02464231662452221\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0189609844237566\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029560208320617676\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.021789034828543663\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0175994411110878\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.012159929610788822\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.018855733796954155\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01372450776398182\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.04662175476551056\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.018697403371334076\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.03637828677892685\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4159824848175049\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5131093263626099\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1466989666223526\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.12426561862230301\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04697201028466225\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03861166536808014\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.030413620173931122\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03299875929951668\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.034777842462062836\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.05846274644136429\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.032622743397951126\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.034394994378089905\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02412133477628231\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029788145795464516\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03951084241271019\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01750202104449272\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018620923161506653\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.017923999577760696\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.013894097879529\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025742029771208763\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006515113171190023\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.021573739126324654\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.370107889175415\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7137002944946289\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.16899710893630981\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0980895385146141\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04788953438401222\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04113750159740448\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.026922941207885742\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.05837678536772728\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.045768119394779205\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.017377186566591263\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0542968288064003\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.032645128667354584\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.030514314770698547\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02872944250702858\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.022773461416363716\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04001704230904579\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02055228501558304\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.008379785344004631\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019915273413062096\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.023685568943619728\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.019706204533576965\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.021967122331261635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3384647369384766\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7952457666397095\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20015501976013184\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09218595921993256\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.056158531457185745\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05006038397550583\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.09409721940755844\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03467591851949692\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02741711586713791\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04211229830980301\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03202825039625168\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02253561094403267\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.07428015768527985\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.019909441471099854\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03144136816263199\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.021566223353147507\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018818078562617302\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01621120795607567\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.026694990694522858\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.029282258823513985\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.023736923933029175\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02567330189049244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3942991495132446\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6408249139785767\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1663869470357895\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08456318825483322\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04973132535815239\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.047211334109306335\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05864674225449562\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02214105986058712\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03663754463195801\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.019059764221310616\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01591753587126732\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02946498990058899\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02922399900853634\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.013650717213749886\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.022957390174269676\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01914716139435768\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.028379736468195915\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019614238291978836\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03381634131073952\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.015608537942171097\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01569514535367489\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.019424760714173317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3419971466064453\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7076360583305359\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20355693995952606\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09157388657331467\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06313380599021912\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04826859384775162\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04032556712627411\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03146468475461006\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.026417354121804237\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03932712972164154\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03233589604496956\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.018830813467502594\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.025475846603512764\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.022869275882840157\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.033727455884218216\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.033312879502773285\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.019688671454787254\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.030562682077288628\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.017420634627342224\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.026948830112814903\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01940901204943657\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.018657419830560684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.385345220565796\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5833980441093445\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1702398955821991\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09140435606241226\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06694945693016052\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.035450126975774765\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.035219546407461166\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.035807736217975616\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02107243798673153\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.020557578653097153\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.020545698702335358\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.034113410860300064\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.024700820446014404\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.026117250323295593\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03648308664560318\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01687144674360752\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.032875917851924896\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.023400476202368736\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.020905165001749992\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.020768875256180763\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.013563945889472961\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.024321570992469788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.40829598903656\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.95563805103302\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.24524208903312683\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.12684805691242218\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05401114374399185\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04055645316839218\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04396292567253113\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.023701680824160576\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03166460990905762\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.024580134078860283\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02612486109137535\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.026406394317746162\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.07605068385601044\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0286334790289402\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03778694570064545\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.018423005938529968\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.028700698167085648\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.030106758698821068\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02164028026163578\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02491815760731697\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0191168375313282\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.021463681012392044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_CNN_BiLSTM_Linear(BertModel.from_pretrained('bert-base-uncased'), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "\n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ABSA/SemEval16 - Task 5 - Restaurants/plots/bert_pt_do_cnn_bilstm_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.404311</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.252189</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>343.167196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995020</td>\n",
       "      <td>0.995020</td>\n",
       "      <td>0.248760</td>\n",
       "      <td>0.995020</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995020</td>\n",
       "      <td>0.249378</td>\n",
       "      <td>340.724913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.512644</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.251603</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.252414</td>\n",
       "      <td>339.733481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994871</td>\n",
       "      <td>0.994871</td>\n",
       "      <td>0.498740</td>\n",
       "      <td>0.994871</td>\n",
       "      <td>0.250244</td>\n",
       "      <td>0.994871</td>\n",
       "      <td>0.249864</td>\n",
       "      <td>344.962219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.436763</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.258551</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.265569</td>\n",
       "      <td>372.016572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.995234</td>\n",
       "      <td>0.995234</td>\n",
       "      <td>0.248809</td>\n",
       "      <td>0.995234</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995234</td>\n",
       "      <td>0.249403</td>\n",
       "      <td>380.239597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994754</td>\n",
       "      <td>0.994754</td>\n",
       "      <td>0.373689</td>\n",
       "      <td>0.994754</td>\n",
       "      <td>0.250251</td>\n",
       "      <td>0.994754</td>\n",
       "      <td>0.249846</td>\n",
       "      <td>371.781314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.248740</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>0.249369</td>\n",
       "      <td>361.676120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.250514</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.250398</td>\n",
       "      <td>388.845268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.248681</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.249339</td>\n",
       "      <td>385.609190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.994953               0.994953               0.404311            0.994953   \n",
       "1  0.995020               0.995020               0.248760            0.995020   \n",
       "2  0.994945               0.994945               0.512644            0.994945   \n",
       "3  0.994871               0.994871               0.498740            0.994871   \n",
       "4  0.994805               0.994805               0.436763            0.994805   \n",
       "5  0.995234               0.995234               0.248809            0.995234   \n",
       "6  0.994754               0.994754               0.373689            0.994754   \n",
       "7  0.994953               0.994953               0.248740            0.994953   \n",
       "8  0.994949               0.994949               0.373745            0.994949   \n",
       "9  0.994723               0.994723               0.248681            0.994723   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.252189        0.994953        0.253635      343.167196  \n",
       "1            0.250000        0.995020        0.249378      340.724913  \n",
       "2            0.251603        0.994945        0.252414      339.733481  \n",
       "3            0.250244        0.994871        0.249864      344.962219  \n",
       "4            0.258551        0.994805        0.265569      372.016572  \n",
       "5            0.250000        0.995234        0.249403      380.239597  \n",
       "6            0.250251        0.994754        0.249846      371.781314  \n",
       "7            0.250000        0.994953        0.249369      361.676120  \n",
       "8            0.250514        0.994949        0.250398      388.845268  \n",
       "9            0.250000        0.994723        0.249339      385.609190  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
