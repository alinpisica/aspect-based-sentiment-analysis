{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_CNN_BiLSTM_Linear import ABSA_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_cnn_bilstm_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_cnn_bilstm_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3877288103103638\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7404388785362244\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.24825474619865417\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.12318629026412964\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.10841437429189682\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05644072964787483\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.042525604367256165\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03805466368794441\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.037024714052677155\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.08306014537811279\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02878505550324917\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.040473099797964096\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.039441999047994614\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03534882515668869\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.028074961155653\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.020895550027489662\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0238555409014225\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.034720923751592636\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.029540766030550003\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.022404303774237633\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.035154521465301514\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0359351746737957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4066082239151\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.8227415084838867\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.2166071981191635\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0825473889708519\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05573026463389397\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.060984622687101364\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.042213473469018936\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03808578476309776\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02432713471353054\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.018148360773921013\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03893457353115082\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.021448533982038498\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.028476005420088768\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029402997344732285\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.024275710806250572\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.012051149271428585\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02590612880885601\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.04330853372812271\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.021024450659751892\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.009939444251358509\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.012552167288959026\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.013685078360140324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.307316780090332\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5571075081825256\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15014371275901794\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0764702633023262\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.048709433525800705\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.035376254469156265\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03400760143995285\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03154882416129112\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02225831337273121\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03260273113846779\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03403220325708389\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.009833565913140774\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.058606766164302826\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.021009957417845726\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.017653094604611397\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02453366108238697\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01893358863890171\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.013695674017071724\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019925391301512718\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02299335040152073\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01789007894694805\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.036926958709955215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4155747890472412\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6681305170059204\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.21383731067180634\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.10148755460977554\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05843774974346161\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05104801431298256\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05312217026948929\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03321919962763786\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02735614776611328\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.022458583116531372\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.030568869784474373\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.023612145334482193\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.033981673419475555\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.024165820330381393\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03297041356563568\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.016112733632326126\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.013277677819132805\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.016489706933498383\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.022941261529922485\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.05800075829029083\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.017456145957112312\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015387666411697865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3719903230667114\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.8415778279304504\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.29205939173698425\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.13795538246631622\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.09954990446567535\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.07138502597808838\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06508298963308334\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0640525296330452\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.053776904940605164\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.08835574239492416\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.043160270899534225\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.05355701595544815\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03827614709734917\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.044726043939590454\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.05536062642931938\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.03965424746274948\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.033282794058322906\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0362309031188488\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.021031737327575684\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03325275331735611\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.03355255722999573\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.029582228511571884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3475145101547241\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6103513240814209\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1868501752614975\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08825531601905823\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05169171467423439\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.033963460475206375\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.044525954872369766\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03127165138721466\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.020488793030381203\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.030114319175481796\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.018720487132668495\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.024425264447927475\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.018927916884422302\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03756776824593544\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.023051923140883446\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.03380894660949707\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.014626150019466877\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01694623753428459\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.011104026809334755\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019572408869862556\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.023321479558944702\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01594668999314308\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3421882390975952\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6935245990753174\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.21493594348430634\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.10174263268709183\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07318063080310822\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.048412125557661057\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.045545704662799835\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.048543695360422134\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04756511002779007\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03783951327204704\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03409802168607712\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.028233032673597336\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022159431129693985\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02252069115638733\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02100745588541031\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0233212448656559\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.023796601220965385\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.022666525095701218\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.014703809283673763\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.024259578436613083\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.013768244534730911\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.022799052298069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.371658205986023\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.855475664138794\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.31971001625061035\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.15657441318035126\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.10560111701488495\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.09046781808137894\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06466003507375717\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.053085412830114365\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05087431147694588\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04656688868999481\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.04053430259227753\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.06078040972352028\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.05132310092449188\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03103068843483925\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.045772846788167953\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04882192984223366\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04208146035671234\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.043097347021102905\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03698267415165901\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019047196954488754\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.027929065749049187\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.019164228811860085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3428397178649902\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7533325552940369\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.22322529554367065\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.12167410552501678\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.052280329167842865\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04178668558597565\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0591340996325016\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.026799004524946213\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03164544329047203\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02397077903151512\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01517350971698761\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02982010319828987\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.026152588427066803\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.026748212054371834\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02760486863553524\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.019757000729441643\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.021311897784471512\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03877515718340874\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.018587803468108177\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019894970580935478\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0163592416793108\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.023454483598470688\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3805582523345947\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7867727875709534\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.2655138671398163\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.13041777908802032\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0907578393816948\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.06977211683988571\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.061322856694459915\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03871573135256767\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03447277098894119\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.033480577170848846\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03941703960299492\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04602330923080444\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.021983806043863297\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02745180018246174\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02627415768802166\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.023072492331266403\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.021457869559526443\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019555557519197464\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02952914871275425\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03120405040681362\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.028183704242110252\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.014789268374443054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_CNN_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "    \n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ABSA/SemEval16 - Task 5 - Restaurants/plots/bert_ft_do_cnn_bilstm_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.248791</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.249394</td>\n",
       "      <td>384.131582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.454240</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.275414</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.294657</td>\n",
       "      <td>394.750716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.457032</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.258099</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.264943</td>\n",
       "      <td>376.528235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995047</td>\n",
       "      <td>0.995047</td>\n",
       "      <td>0.548766</td>\n",
       "      <td>0.995047</td>\n",
       "      <td>0.251881</td>\n",
       "      <td>0.995047</td>\n",
       "      <td>0.253108</td>\n",
       "      <td>372.622299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.249376</td>\n",
       "      <td>387.927254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.995223</td>\n",
       "      <td>0.995223</td>\n",
       "      <td>0.428305</td>\n",
       "      <td>0.995223</td>\n",
       "      <td>0.257758</td>\n",
       "      <td>0.995223</td>\n",
       "      <td>0.264284</td>\n",
       "      <td>398.892684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995078</td>\n",
       "      <td>0.995078</td>\n",
       "      <td>0.248772</td>\n",
       "      <td>0.995078</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995078</td>\n",
       "      <td>0.249385</td>\n",
       "      <td>381.397712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.248779</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.249388</td>\n",
       "      <td>371.586913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.498881</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.250577</td>\n",
       "      <td>372.294208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994836</td>\n",
       "      <td>0.994836</td>\n",
       "      <td>0.248725</td>\n",
       "      <td>0.994836</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.994836</td>\n",
       "      <td>0.249361</td>\n",
       "      <td>376.453127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.995164               0.995164               0.248791            0.995164   \n",
       "1  0.995117               0.995117               0.454240            0.995117   \n",
       "2  0.994734               0.994734               0.457032            0.994734   \n",
       "3  0.995047               0.995047               0.548766            0.995047   \n",
       "4  0.995023               0.995023               0.248756            0.995023   \n",
       "5  0.995223               0.995223               0.428305            0.995223   \n",
       "6  0.995078               0.995078               0.248772            0.995078   \n",
       "7  0.995117               0.995117               0.248779            0.995117   \n",
       "8  0.995477               0.995477               0.498881            0.995477   \n",
       "9  0.994836               0.994836               0.248725            0.994836   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.250000        0.995164        0.249394      384.131582  \n",
       "1            0.275414        0.995117        0.294657      394.750716  \n",
       "2            0.258099        0.994734        0.264943      376.528235  \n",
       "3            0.251881        0.995047        0.253108      372.622299  \n",
       "4            0.250000        0.995023        0.249376      387.927254  \n",
       "5            0.257758        0.995223        0.264284      398.892684  \n",
       "6            0.250000        0.995078        0.249385      381.397712  \n",
       "7            0.250000        0.995117        0.249388      371.586913  \n",
       "8            0.250568        0.995477        0.250577      372.294208  \n",
       "9            0.250000        0.994836        0.249361      376.453127  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
