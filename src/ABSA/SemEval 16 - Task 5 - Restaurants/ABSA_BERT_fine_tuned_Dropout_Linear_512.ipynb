{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from absa_models.ABSA_BERT_Dropout_Linear import ABSA_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ABSA_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>absa_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                           absa_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ABSA/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 4), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.502254843711853\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.016529351472854614\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.01436641626060009\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0038785499054938555\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.013922779820859432\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.005508235655725002\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.00804922915995121\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.005616351496428251\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.006902816239744425\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.014564670622348785\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.009878995828330517\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.011151284910738468\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.006698111537843943\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.004010316915810108\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00269548618234694\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0037554088048636913\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01226247102022171\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.00223394762724638\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.009667331352829933\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.004780913703143597\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00469432445243001\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0065850247628986835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.463208556175232\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0261706355959177\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.02632233500480652\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.009504584595561028\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.010320761241018772\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.013255215249955654\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.00992375984787941\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.007401903625577688\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.010724782943725586\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0063756671734154224\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.002112202811986208\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.013976559974253178\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.008522032760083675\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007790213916450739\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.006083075888454914\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.017984537407755852\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0035385589580982924\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.012331734411418438\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0072256941348314285\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0032241467852145433\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.003487638896331191\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005718282423913479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.378906488418579\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02422570064663887\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.022561803460121155\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.015224645845592022\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.007838728837668896\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.012695328332483768\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.005160419270396233\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.008263268508017063\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.011839320883154869\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.006531660910695791\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.007484905421733856\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.003023012075573206\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.018769459798932076\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.003990563564002514\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.006824523210525513\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.005231273826211691\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.00479878019541502\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.005909568164497614\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00804088544100523\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.012960526160895824\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.011200519278645515\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005491940770298243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.3347448110580444\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.016775814816355705\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.011515343561768532\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.00799565389752388\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.010332022793591022\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.008758124895393848\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.007452616933733225\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.010826055891811848\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.014790065586566925\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.013598555698990822\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.002426711143925786\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.00822147261351347\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.009896463714540005\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.003619661321863532\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0062504601664841175\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008598885498940945\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.004851874429732561\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009190152399241924\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.006799486931413412\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.004632612690329552\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006773354485630989\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.014348515309393406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 2.1908376216888428\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.025330955162644386\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.016029011458158493\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.020597616210579872\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.01074772048741579\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.010441700927913189\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.015601415187120438\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.005435822531580925\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.006173683330416679\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.005631486885249615\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.011626170948147774\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.005573205184191465\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.00798778422176838\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007005798164755106\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009615872986614704\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.00450839102268219\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01677042432129383\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.003325630910694599\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.010796118527650833\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.013643879443407059\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010028965771198273\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007154362741857767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2367304563522339\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02112537808716297\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.011727012693881989\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.00860232301056385\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.007023172918707132\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.004379098303616047\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.009372330270707607\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.00922588910907507\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.005950859282165766\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.007644865196198225\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.010263134725391865\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.009916861541569233\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.01206065621227026\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0062291622161865234\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01242311391979456\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.005626413505524397\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0030425379518419504\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0034753475338220596\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.002957710763439536\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.008236036635935307\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006592927500605583\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01105156634002924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4871909618377686\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.01649247668683529\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.008518478833138943\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.008307239040732384\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.009178925305604935\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.009212582372128963\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.006507448852062225\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.007165086921304464\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.00691593624651432\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0066153923980891705\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.006367719732224941\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.003254201263189316\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.00655657472088933\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.006103167776018381\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01576693169772625\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.005754134617745876\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.017108719795942307\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009049875661730766\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0025601107627153397\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006602803710848093\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009970132261514664\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.027679817751049995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2049199342727661\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02512434683740139\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.024485869333148003\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.011189650744199753\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.01134723424911499\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.003186592133715749\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.013351728208363056\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.010273001156747341\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.00802579801529646\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01685628853738308\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.005811051465570927\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.00554721150547266\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.008109566755592823\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.005233342759311199\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.003608645172789693\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.016452262178063393\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01573602482676506\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.011897641234099865\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00828276015818119\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.010963255539536476\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.004818348679691553\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009067228995263577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0988523960113525\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02853679284453392\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.016795320436358452\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.012678098864853382\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.004039342049509287\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0137419318780303\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.010943427681922913\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0077042654156684875\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02211759053170681\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.012345709837973118\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.007663092575967312\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.006061469670385122\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.004453578963875771\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007163146045058966\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.005837799981236458\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.009893402457237244\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.006726175080984831\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.005032689776271582\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.007500397507101297\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.010952244512736797\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.024894537404179573\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.00318545033223927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4918681383132935\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.023114100098609924\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.02297290228307247\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.010746589861810207\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.009593754075467587\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0066449022851884365\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.005382112227380276\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.010400953702628613\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.015848226845264435\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.009098908863961697\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.00862383097410202\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.007520156446844339\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.020851224660873413\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.00462925573810935\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.008697249926626682\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008650162257254124\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0043198117054998875\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009333766996860504\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00687813526019454\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.004409067798405886\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.007812882773578167\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0047290693037211895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ABSA_BERT_Dropout_Linear(torch.load(BERT_FINE_TUNED_PATH), dropout=0.3, no_out_labels=4, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "    \n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ABSA/SemEval16 - Task 5 - Restaurants/plots/bert_ft_do_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.661738</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.483807</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.471105</td>\n",
       "      <td>329.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.670685</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.489405</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.453582</td>\n",
       "      <td>329.905853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997797</td>\n",
       "      <td>0.997797</td>\n",
       "      <td>0.589022</td>\n",
       "      <td>0.997797</td>\n",
       "      <td>0.476299</td>\n",
       "      <td>0.997797</td>\n",
       "      <td>0.448434</td>\n",
       "      <td>328.510896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.679552</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.479346</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.461071</td>\n",
       "      <td>329.259464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.416478</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.482039</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>0.443870</td>\n",
       "      <td>330.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.418082</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.481633</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.444798</td>\n",
       "      <td>328.952955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.413388</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.479711</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>327.921987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997898</td>\n",
       "      <td>0.997898</td>\n",
       "      <td>0.595042</td>\n",
       "      <td>0.997898</td>\n",
       "      <td>0.512310</td>\n",
       "      <td>0.997898</td>\n",
       "      <td>0.497251</td>\n",
       "      <td>317.634438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998051</td>\n",
       "      <td>0.998051</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.998051</td>\n",
       "      <td>0.555875</td>\n",
       "      <td>0.998051</td>\n",
       "      <td>0.563823</td>\n",
       "      <td>315.369358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.617625</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.482242</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.457059</td>\n",
       "      <td>333.940730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.998043               0.998043               0.661738            0.998043   \n",
       "1  0.997840               0.997840               0.670685            0.997840   \n",
       "2  0.997797               0.997797               0.589022            0.997797   \n",
       "3  0.998020               0.998020               0.679552            0.998020   \n",
       "4  0.997828               0.997828               0.416478            0.997828   \n",
       "5  0.997750               0.997750               0.418082            0.997750   \n",
       "6  0.997848               0.997848               0.413388            0.997848   \n",
       "7  0.997898               0.997898               0.595042            0.997898   \n",
       "8  0.998051               0.998051               0.630952            0.998051   \n",
       "9  0.997848               0.997848               0.617625            0.997848   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.483807        0.998043        0.471105      329.770822  \n",
       "1            0.489405        0.997840        0.453582      329.905853  \n",
       "2            0.476299        0.997797        0.448434      328.510896  \n",
       "3            0.479346        0.998020        0.461071      329.259464  \n",
       "4            0.482039        0.997828        0.443870      330.423900  \n",
       "5            0.481633        0.997750        0.444798      328.952955  \n",
       "6            0.479711        0.997848        0.440952      327.921987  \n",
       "7            0.512310        0.997898        0.497251      317.634438  \n",
       "8            0.555875        0.998051        0.563823      315.369358  \n",
       "9            0.482242        0.997848        0.457059      333.940730  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
