{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from models.BERT_Dropout_CNN_BiLSTM_Linear import BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_cnn_bilstm_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_cnn_bilstm_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1272287368774414\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.504747211933136\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1400931477546692\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06927359849214554\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.038700785487890244\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.048374325037002563\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0359799824655056\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.028781231492757797\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.027132274582982063\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.021517794579267502\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.022560089826583862\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04680657759308815\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02364029921591282\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.018369892612099648\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.017621204257011414\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.018922442570328712\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.023588869720697403\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.018757443875074387\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01602332666516304\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.017506178468465805\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.007077195215970278\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02284635603427887\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.091916799545288\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4953076243400574\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13243624567985535\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06758469343185425\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06475821137428284\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.027183065190911293\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.07278900593519211\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022772351279854774\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.014620579779148102\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.022133605554699898\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02358103357255459\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01403912715613842\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022482626140117645\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.017963089048862457\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.010780369862914085\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.00971606932580471\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.011892744340002537\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03813550993800163\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01603376306593418\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0159606896340847\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.022267619147896767\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.034328751266002655\n",
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0874860286712646\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4285126328468323\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13151895999908447\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.061549361795186996\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03565859794616699\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.029088178649544716\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02792835421860218\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.028599314391613007\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0318453349173069\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01668599620461464\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.022193925455212593\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.034482188522815704\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02046356163918972\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01995731331408024\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0324711911380291\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.020709307864308357\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015538292936980724\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019590631127357483\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008983264677226543\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01932854764163494\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.028841225430369377\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011408376507461071\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0481988191604614\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4158034920692444\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.10938005149364471\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.05977369099855423\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.052426546812057495\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0338754765689373\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.029482562094926834\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.023218529298901558\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.018535666167736053\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023953108116984367\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.023683924227952957\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02625431679189205\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.029202140867710114\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029453299939632416\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03554007411003113\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.017424125224351883\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018992288038134575\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.010863595642149448\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.007378151640295982\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01675419881939888\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.024569697678089142\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011561193503439426\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1276098489761353\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5816333889961243\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13490080833435059\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06611240655183792\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0488482266664505\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.028417576104402542\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.030796214938163757\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03750031813979149\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.025970986112952232\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01763240620493889\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0250946506857872\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.034486059099435806\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015577886253595352\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03771159052848816\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.031821440905332565\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.03500548377633095\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.009879008866846561\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009584140963852406\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02596326917409897\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.008541646413505077\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.012788036838173866\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011068659834563732\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0440185070037842\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4733579158782959\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1567688286304474\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06963396072387695\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03818951174616814\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03190288320183754\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.037322428077459335\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03503536432981491\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.022636665031313896\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.015356933698058128\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.024260489270091057\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020387789234519005\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015335899777710438\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.014865659177303314\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03724079951643944\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.00999514851719141\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.027006395161151886\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009814371354877949\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01117249857634306\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019108770415186882\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009956364519894123\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009686768986284733\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1010233163833618\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5871406197547913\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20696739852428436\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.11411069333553314\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06573054939508438\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05770270526409149\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.05268684774637222\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.05751299113035202\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03348446637392044\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03683873265981674\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.039267055690288544\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0568070225417614\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02933376654982567\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0427461601793766\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02587382309138775\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04161200672388077\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02863989770412445\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02856934815645218\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.029872644692659378\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02614668384194374\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.02500680461525917\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.024131471291184425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1305608749389648\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6343294978141785\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1676105111837387\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07165433466434479\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04187655821442604\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.033249273896217346\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.027294183149933815\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02317405492067337\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0308480653911829\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03605445474386215\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.025922199711203575\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.026304323226213455\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.025276776403188705\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01078348234295845\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01691964641213417\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.018830932676792145\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.017202500253915787\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01230141893029213\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.05401523411273956\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0349525511264801\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0051119364798069\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011615523137152195\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0812221765518188\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5127729773521423\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15969130396842957\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0679943636059761\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06101905182003975\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0391811728477478\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.030434761196374893\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.028597110882401466\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.021990709006786346\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.022205933928489685\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01915883831679821\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020039435476064682\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.024887854233384132\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03571387007832527\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.022863248363137245\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.02975897677242756\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.04218185320496559\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02601863630115986\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012507440522313118\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0388784259557724\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01696918159723282\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01783486269414425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.137380599975586\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7412877678871155\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.2812727689743042\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.1299826055765152\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.09861220419406891\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.07226618379354477\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.061550747603178024\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.056143663823604584\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05792200565338135\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04020576551556587\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0824773907661438\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03838009759783745\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03935406729578972\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.036269329488277435\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.051103074103593826\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.04897179827094078\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.03364236652851105\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.030694471672177315\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.025077488273382187\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.03385022282600403\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.030994880944490433\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02616981230676174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = BERT_Dropout_CNN_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.bert, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.631969</td>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.353304</td>\n",
       "      <td>0.995188</td>\n",
       "      <td>0.369719</td>\n",
       "      <td>363.689629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995359</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>0.619140</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>0.372968</td>\n",
       "      <td>0.995359</td>\n",
       "      <td>0.402289</td>\n",
       "      <td>360.759269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994969</td>\n",
       "      <td>0.994969</td>\n",
       "      <td>0.643920</td>\n",
       "      <td>0.994969</td>\n",
       "      <td>0.366024</td>\n",
       "      <td>0.994969</td>\n",
       "      <td>0.390377</td>\n",
       "      <td>360.192474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.532637</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.995227</td>\n",
       "      <td>0.384270</td>\n",
       "      <td>368.186726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.713497</td>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.398690</td>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.429373</td>\n",
       "      <td>377.635806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.627876</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.373912</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.401551</td>\n",
       "      <td>384.244402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.331647</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.994934</td>\n",
       "      <td>0.332487</td>\n",
       "      <td>361.655894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994707</td>\n",
       "      <td>0.994707</td>\n",
       "      <td>0.551313</td>\n",
       "      <td>0.994707</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.994707</td>\n",
       "      <td>0.409239</td>\n",
       "      <td>361.001662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.498425</td>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.362664</td>\n",
       "      <td>0.994957</td>\n",
       "      <td>0.382483</td>\n",
       "      <td>360.938213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.331661</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.332495</td>\n",
       "      <td>360.835322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.995188               0.995188               0.631969            0.995188   \n",
       "1  0.995359               0.995359               0.619140            0.995359   \n",
       "2  0.994969               0.994969               0.643920            0.994969   \n",
       "3  0.995227               0.995227               0.532637            0.995227   \n",
       "4  0.995559               0.995559               0.713497            0.995559   \n",
       "5  0.995316               0.995316               0.627876            0.995316   \n",
       "6  0.994934               0.994934               0.331647            0.994934   \n",
       "7  0.994707               0.994707               0.551313            0.994707   \n",
       "8  0.994957               0.994957               0.498425            0.994957   \n",
       "9  0.994984               0.994984               0.331661            0.994984   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.353304        0.995188        0.369719      363.689629  \n",
       "1            0.372968        0.995359        0.402289      360.759269  \n",
       "2            0.366024        0.994969        0.390377      360.192474  \n",
       "3            0.364972        0.995227        0.384270      368.186726  \n",
       "4            0.398690        0.995559        0.429373      377.635806  \n",
       "5            0.373912        0.995316        0.401551      384.244402  \n",
       "6            0.333332        0.994934        0.332487      361.655894  \n",
       "7            0.384984        0.994707        0.409239      361.001662  \n",
       "8            0.362664        0.994957        0.382483      360.938213  \n",
       "9            0.333333        0.994984        0.332495      360.835322  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
