{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from ate_models.ATE_BERT_Dropout_CNN_BiLSTM_Linear import ATE_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_cnn_bilstm_linear.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_cnn_bilstm_linear.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0542467832565308\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5321171283721924\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1747092455625534\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08273252844810486\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04575229063630104\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.08083061873912811\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.029120909050107002\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02484729327261448\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.019432995468378067\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03155076503753662\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.027576666325330734\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01648276299238205\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.030881445854902267\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02345050871372223\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02026584930717945\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01580442115664482\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.019574681296944618\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0244335625320673\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.018140727654099464\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01870858483016491\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006666719913482666\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016009896993637085\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.049507975578308\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.46677231788635254\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13848435878753662\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.060173071920871735\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.044727593660354614\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.038604918867349625\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03149598464369774\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.016655707731842995\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05292108654975891\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01617189683020115\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.048739220947027206\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02431444823741913\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.019726984202861786\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.020046822726726532\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01700408197939396\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015774020925164223\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.017053551971912384\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.016923123970627785\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019128458574414253\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.028906596824526787\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.030495954677462578\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016081316396594048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0872057676315308\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5923060178756714\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1414772868156433\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06604524701833725\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04842788726091385\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.027280062437057495\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03161023557186127\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.023147720843553543\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.047526001930236816\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.015185251832008362\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.010246201418340206\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020910557359457016\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.01642727293074131\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.017603376880288124\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.018378645181655884\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.011199269443750381\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01900157332420349\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02291872352361679\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0365067794919014\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.017014656215906143\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010330899618566036\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.019201816990971565\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.091205358505249\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5605055093765259\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20633862912654877\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.10504426807165146\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0671929344534874\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05106273293495178\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.041548822075128555\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0357440747320652\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03657713159918785\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.03077351301908493\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03243047371506691\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03128992021083832\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022767750546336174\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.022617606446146965\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.026471910998225212\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01507987454533577\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018940551206469536\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.026837043464183807\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.042098067700862885\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.027098258957266808\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.018087100237607956\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.020226603373885155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0972031354904175\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5322515368461609\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15784379839897156\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08054593205451965\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04545075446367264\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.038978997617959976\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.030718455091118813\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.027123937383294106\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03204634413123131\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02087046392261982\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02437399886548519\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.022309063002467155\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.026360150426626205\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01920643262565136\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.019399791955947876\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.024579161778092384\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.012040296569466591\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03633512929081917\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.014629440382122993\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.010038964450359344\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01433086022734642\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.022798972204327583\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0417780876159668\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4090331196784973\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.11653154343366623\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.05901549011468887\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0640765056014061\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.025496676564216614\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03420289605855942\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02786502242088318\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.015283425338566303\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.016814833506941795\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.026238657534122467\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.05803685262799263\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.03373962268233299\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.022462625056505203\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.011286448687314987\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008679884485900402\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.016815805807709694\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019347336143255234\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03512918949127197\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.014851645566523075\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.012948957271873951\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.017233900725841522\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0810357332229614\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5309256911277771\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15850678086280823\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.09471733868122101\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07018206268548965\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04031480476260185\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.08684946596622467\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.04125776141881943\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02453620545566082\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.037767235189676285\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.028269868344068527\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01174083724617958\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.016209853813052177\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.016391271725296974\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03264929726719856\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.021921444684267044\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01946060173213482\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03017880953848362\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01985936053097248\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.015866367146372795\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.015148433856666088\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01800323650240898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.114091157913208\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5482444167137146\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13233618438243866\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0622732937335968\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.07565288245677948\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0391237847507\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.021603580564260483\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.026238104328513145\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.018476370722055435\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023417802527546883\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02657862938940525\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014550133608281612\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.009722390212118626\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.027243467047810555\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.017576318234205246\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.026014912873506546\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.032570838928222656\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01274008210748434\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.029426870867609978\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01649051532149315\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009572253562510014\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01936914026737213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0790808200836182\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4406585395336151\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13892026245594025\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.08815524727106094\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.039858244359493256\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02615087293088436\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.024503469467163086\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03498710319399834\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.024822881445288658\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01935102790594101\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.027249792590737343\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04391122981905937\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.017189139500260353\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.017277754843235016\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01237617339938879\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01241897139698267\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018637463450431824\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03461555764079094\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00945243053138256\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.02078622579574585\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.013669885694980621\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.011483448557555676\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1359201669692993\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.7797794938087463\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.20199741423130035\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0762934461236\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.049978598952293396\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03955967351794243\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03322742506861687\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02445617876946926\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.027908308431506157\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.019325509667396545\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.029254266992211342\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.016441917046904564\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.014936731196939945\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.04539239779114723\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.021996742114424706\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015051564201712608\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.013139725662767887\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.04468398913741112\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01711186394095421\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.017740361392498016\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.028980053961277008\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.00934530422091484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ATE_BERT_Dropout_CNN_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.620298</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.364183</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.387661</td>\n",
       "      <td>364.732296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.459046</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.356646</td>\n",
       "      <td>0.994926</td>\n",
       "      <td>0.372002</td>\n",
       "      <td>361.319139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.740861</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.348298</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.361377</td>\n",
       "      <td>361.295934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.450783</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.335284</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.336382</td>\n",
       "      <td>360.377202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.994781</td>\n",
       "      <td>0.994781</td>\n",
       "      <td>0.582125</td>\n",
       "      <td>0.994781</td>\n",
       "      <td>0.369920</td>\n",
       "      <td>0.994781</td>\n",
       "      <td>0.392177</td>\n",
       "      <td>360.619777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.542740</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.348508</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.360780</td>\n",
       "      <td>360.779933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995008</td>\n",
       "      <td>0.995008</td>\n",
       "      <td>0.455764</td>\n",
       "      <td>0.995008</td>\n",
       "      <td>0.368660</td>\n",
       "      <td>0.995008</td>\n",
       "      <td>0.387644</td>\n",
       "      <td>360.821728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.452215</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.345377</td>\n",
       "      <td>0.994711</td>\n",
       "      <td>0.354418</td>\n",
       "      <td>362.203332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.520803</td>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.359041</td>\n",
       "      <td>0.994910</td>\n",
       "      <td>0.375594</td>\n",
       "      <td>365.873135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.460763</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.353891</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.368064</td>\n",
       "      <td>363.622211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.994949               0.994949               0.620298            0.994949   \n",
       "1  0.994926               0.994926               0.459046            0.994926   \n",
       "2  0.995203               0.995203               0.740861            0.995203   \n",
       "3  0.995172               0.995172               0.450783            0.995172   \n",
       "4  0.994781               0.994781               0.582125            0.994781   \n",
       "5  0.994938               0.994938               0.542740            0.994938   \n",
       "6  0.995008               0.995008               0.455764            0.995008   \n",
       "7  0.994711               0.994711               0.452215            0.994711   \n",
       "8  0.994910               0.994910               0.520803            0.994910   \n",
       "9  0.995102               0.995102               0.460763            0.995102   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.364183        0.994949        0.387661      364.732296  \n",
       "1            0.356646        0.994926        0.372002      361.319139  \n",
       "2            0.348298        0.995203        0.361377      361.295934  \n",
       "3            0.335284        0.995172        0.336382      360.377202  \n",
       "4            0.369920        0.994781        0.392177      360.619777  \n",
       "5            0.348508        0.994938        0.360780      360.779933  \n",
       "6            0.368660        0.995008        0.387644      360.821728  \n",
       "7            0.345377        0.994711        0.354418      362.203332  \n",
       "8            0.359041        0.994910        0.375594      365.873135  \n",
       "9            0.353891        0.995102        0.368064      363.622211  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60f74211c8095d4d69bea747ac312f2fd52777f7ee1c791c3155581964756685"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
