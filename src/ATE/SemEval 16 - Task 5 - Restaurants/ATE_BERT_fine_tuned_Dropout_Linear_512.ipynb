{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from ate_models.ATE_BERT_Dropout_Linear import ATE_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2816704511642456\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.026416700333356857\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.005662949755787849\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.011709999293088913\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.008697126992046833\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.01948731020092964\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.005101105663925409\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.010114021599292755\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.011318616569042206\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.004760406445711851\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.007759466301649809\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0039798603393137455\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.002601640997454524\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0028219192754477262\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009976202622056007\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.006054909434169531\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.009006625972688198\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.00340395444072783\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.04789776727557182\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.005797599442303181\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009727032855153084\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0031037027947604656\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.4680713415145874\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.009880517609417439\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.013645901344716549\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.006544819101691246\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.006229922641068697\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.007780623156577349\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0065716165117919445\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.005090637132525444\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.006859465967863798\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0032623561564832926\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0019936831668019295\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0032425890676677227\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.006306836847215891\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.006708056665956974\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0012203488731756806\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.005220637656748295\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.005807382985949516\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.00817185454070568\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0007369949598796666\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0094023197889328\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.004271714482456446\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007478275336325169\n",
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0448565483093262\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.011599251069128513\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0170813649892807\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.007126534357666969\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.008809789083898067\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.008404474705457687\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.004749760497361422\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.005083160009235144\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.007645096629858017\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.004340546205639839\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.006628287956118584\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0040963017381727695\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0017570399213582277\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0014690735843032598\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00467316061258316\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010101617313921452\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.004074221011251211\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0014640759909525514\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008211668580770493\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006536593660712242\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006576967425644398\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0009399814298376441\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.5686129331588745\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.017369039356708527\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0051590995863080025\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.004828962031751871\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.003420082153752446\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.013860650360584259\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.008577709086239338\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0032792941201478243\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.016140006482601166\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0028549719136208296\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.005789798218756914\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0031526628881692886\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0056495037861168385\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.004246716853231192\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00391735415905714\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.006026077084243298\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.006042421795427799\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0016258582472801208\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.004909145180135965\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.011011228896677494\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00880307238548994\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.006515963468700647\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.7258855700492859\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.010066785849630833\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.007057438138872385\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.012583265081048012\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.004274494480341673\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.005345708690583706\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.010052721947431564\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.007260638754814863\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.004369637928903103\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.008021362125873566\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.003743477165699005\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0020687663927674294\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.003843712154775858\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0077651552855968475\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0034275350626558065\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.003793088486418128\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.009809859097003937\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.012447282671928406\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0020770560950040817\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.005286868195980787\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0053603556007146835\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009256326593458652\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.6787810921669006\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.011044207029044628\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.007668111007660627\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.007577905431389809\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.016175569966435432\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.002924172906205058\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.003288978710770607\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0043561882339417934\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.005111035890877247\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.003016906324774027\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.013731495477259159\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0028041501063853502\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.009127027355134487\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0035145380534231663\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0023730434477329254\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0006823030416853726\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.00427898857742548\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0024601996410638094\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008215565234422684\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.002075119176879525\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0019465534714981914\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005576745141297579\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2573890686035156\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.010243899188935757\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.009072858840227127\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.009700289927423\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.01327463611960411\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0080141955986619\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.006783812772482634\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.006759032141417265\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.008059000596404076\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.00859034899622202\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.002089231973513961\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.009382348507642746\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.013529935851693153\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.008357842452824116\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0038986424915492535\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0054110074415802956\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0067687504924833775\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0030066529288887978\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.00568814855068922\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0049608745612204075\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01081998273730278\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005029980093240738\n",
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1129218339920044\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.01704217679798603\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.007565875072032213\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.010142899118363857\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.011573519557714462\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.005000746343284845\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.010034624487161636\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.003093566745519638\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.00575642567127943\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.004950658418238163\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.00808764062821865\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.004779763985425234\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0032766638323664665\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007228098809719086\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.009337668307125568\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0014573277439922094\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.007226705085486174\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0031650203745812178\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0046303425915539265\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.002796699060127139\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.008237781003117561\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.0018871770007535815\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.745067834854126\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.006507375277578831\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0071250759065151215\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.013201165944337845\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.003065465483814478\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.018158044666051865\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.00521246250718832\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0036922162398695946\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.013358363881707191\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.008338334038853645\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.004412471782416105\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0006621580687351525\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.009240703657269478\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.006856437772512436\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.005248579662293196\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.004890399985015392\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0012992265401408076\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01232248917222023\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.005543550942093134\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0011822644155472517\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.008522550575435162\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.00965031236410141\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0225334167480469\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.019657621160149574\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.007970716804265976\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.002537828404456377\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.01618742011487484\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.003140005050227046\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.011747580021619797\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.016566190868616104\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.016075069084763527\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.006725567393004894\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0026889063883572817\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.002884066430851817\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.008908877149224281\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.003272476838901639\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.014744208194315434\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.004859592765569687\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008448012173175812\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.006699493154883385\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012872549705207348\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006842988543212414\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0034682131372392178\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.010897240601480007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ATE_BERT_Dropout_Linear(torch.load(BERT_FINE_TUNED_PATH), dropout=0.3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "\n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ATE/SemEval16 - Task 5 - Restaurants/plots/bert_ft_do_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997996</td>\n",
       "      <td>0.997996</td>\n",
       "      <td>0.800478</td>\n",
       "      <td>0.997996</td>\n",
       "      <td>0.813319</td>\n",
       "      <td>0.997996</td>\n",
       "      <td>0.804993</td>\n",
       "      <td>329.256580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.814916</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.880485</td>\n",
       "      <td>0.998199</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>326.390977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.884575</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.880955</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.881542</td>\n",
       "      <td>326.846561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.839204</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.868192</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.851654</td>\n",
       "      <td>327.236537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.882786</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.905942</td>\n",
       "      <td>0.998824</td>\n",
       "      <td>0.893723</td>\n",
       "      <td>326.723793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.922546</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.872903</td>\n",
       "      <td>0.998938</td>\n",
       "      <td>0.892525</td>\n",
       "      <td>327.466753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998738</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>0.885994</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>0.875813</td>\n",
       "      <td>0.998738</td>\n",
       "      <td>0.880598</td>\n",
       "      <td>327.427940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.886257</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.857962</td>\n",
       "      <td>0.998555</td>\n",
       "      <td>0.867593</td>\n",
       "      <td>324.858705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.906330</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.914802</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>326.277990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.998797</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>0.908485</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>0.861614</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>325.239529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.997996               0.997996               0.800478            0.997996   \n",
       "1  0.998199               0.998199               0.814916            0.998199   \n",
       "2  0.998711               0.998711               0.884575            0.998711   \n",
       "3  0.998437               0.998437               0.839204            0.998437   \n",
       "4  0.998824               0.998824               0.882786            0.998824   \n",
       "5  0.998938               0.998938               0.922546            0.998938   \n",
       "6  0.998738               0.998738               0.885994            0.998738   \n",
       "7  0.998555               0.998555               0.886257            0.998555   \n",
       "8  0.998973               0.998973               0.906330            0.998973   \n",
       "9  0.998797               0.998797               0.908485            0.998797   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.813319        0.997996        0.804993      329.256580  \n",
       "1            0.880485        0.998199        0.845588      326.390977  \n",
       "2            0.880955        0.998711        0.881542      326.846561  \n",
       "3            0.868192        0.998437        0.851654      327.236537  \n",
       "4            0.905942        0.998824        0.893723      326.723793  \n",
       "5            0.872903        0.998938        0.892525      327.466753  \n",
       "6            0.875813        0.998738        0.880598      327.427940  \n",
       "7            0.857962        0.998555        0.867593      324.858705  \n",
       "8            0.914802        0.998973        0.910278      326.277990  \n",
       "9            0.861614        0.998797        0.882979      325.239529  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
