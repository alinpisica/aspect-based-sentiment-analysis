{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from ate_models.ATE_BERT_Dropout_BiLSTM_Linear import ATE_BERT_Dropout_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_bilstm_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_bilstm_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss_fn(outputs.view(-1, 3), tags_tensors.view(-1)).item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.2063688039779663\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0737944096326828\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04147915914654732\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.026891347020864487\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03880473971366882\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05755380541086197\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03910692036151886\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.06783652305603027\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02082475833594799\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.014848523773252964\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01815630868077278\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.00851296354085207\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.023495078086853027\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.029160290956497192\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00688580609858036\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.00995971355587244\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.017245374619960785\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01528118085116148\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01711527444422245\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006103952880948782\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.02460436522960663\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.014389856718480587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1922657489776611\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0787394642829895\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.06290058046579361\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0365154966711998\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.033398084342479706\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.023028777912259102\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.01619075983762741\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022594241425395012\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04971852898597717\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.028270291164517403\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02184840478003025\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.016185887157917023\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.029658226296305656\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02600334770977497\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01872141659259796\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.014292692765593529\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.023432036861777306\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.021326348185539246\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.010057385079562664\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.022190408781170845\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.012456605210900307\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.006400661077350378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1573076248168945\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.07576719671487808\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03587526082992554\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03740232437849045\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.028516853228211403\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.028219707310199738\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02535332925617695\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.023552529513835907\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.026185275986790657\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.015478670597076416\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02337920479476452\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.012239694595336914\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0245584174990654\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.007301578298211098\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.018940480425953865\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.017207473516464233\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015594132244586945\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.012094859965145588\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01719849370419979\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.006439314689487219\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010775101371109486\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005760812200605869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0058449506759644\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.08923798054456711\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04624124616384506\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.048654649406671524\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.041631318628787994\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.026344450190663338\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.06966008245944977\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.030354542657732964\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02425297163426876\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.024195801466703415\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02524140104651451\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.02003200724720955\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015851007774472237\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.027127645909786224\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.015916693955659866\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.023409340530633926\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.00825424212962389\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.017187902703881264\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01201349776238203\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.007370964158326387\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01087060384452343\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009115270338952541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1548683643341064\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0788545310497284\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.052866119891405106\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0435960479080677\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.038500603288412094\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.023997534066438675\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.022731035947799683\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.049260396510362625\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.016222096979618073\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.009482599794864655\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01934005320072174\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.0299686286598444\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.027496760711073875\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.019040068611502647\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.037503499537706375\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015362799167633057\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.007967686280608177\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.01667335443198681\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.008566330187022686\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0238344706594944\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.005733921658247709\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.008064871653914452\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.098507285118103\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.10584590584039688\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04170243814587593\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06332554668188095\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05701975151896477\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.0339888371527195\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.033595647662878036\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022150035947561264\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0077893417328596115\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.020987872034311295\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01774979941546917\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.022181671112775803\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.014580147340893745\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0122537137940526\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.01146626379340887\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015252206474542618\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.013955424539744854\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.024287061765789986\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.009167972952127457\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.008257942274212837\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010670195333659649\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.010167202912271023\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1342971324920654\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.059465162456035614\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.031907085329294205\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03412390872836113\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03338059037923813\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.037690937519073486\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.045573294162750244\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02113201655447483\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.027744701132178307\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.026386968791484833\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.028958018869161606\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.016664870083332062\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.040248267352581024\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.008020872250199318\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.014734319411218166\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.020677341148257256\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.005988969933241606\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019919009879231453\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0038700320292264223\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.014945200644433498\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.008783628232777119\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01376687828451395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1045013666152954\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.0670560747385025\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03397452086210251\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.02515069954097271\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.025508342310786247\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.016570085659623146\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04859165474772453\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022208470851182938\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.013768485747277737\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.021118639037013054\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.019485848024487495\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.031694862991571426\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.02423218823969364\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.011454087682068348\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.011909719556570053\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.019987722858786583\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01491188071668148\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.016313910484313965\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.017428305000066757\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.022777631878852844\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.007957478053867817\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007337816525250673\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.079488754272461\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.06514322757720947\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.03726688027381897\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.035309020429849625\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.030705975368618965\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.026201816275715828\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.0408983938395977\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02012835070490837\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.05361479893326759\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.013235820457339287\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.03349026292562485\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014781039208173752\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.027352051809430122\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.013144792057573795\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.010974795557558537\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015576031990349293\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.012991639785468578\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.010919412598013878\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.014833183027803898\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.016187576577067375\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.009624145925045013\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.017989885061979294\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1330907344818115\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.07327054440975189\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04750906303524971\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.056217607110738754\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.036677610129117966\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02481328509747982\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02100805938243866\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.017339227721095085\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.03518619388341904\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.06162015721201897\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.031272344291210175\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01981360837817192\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.024263914674520493\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.040693942457437515\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.011284870095551014\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.017241284251213074\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.022992417216300964\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009950266219675541\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.028294013813138008\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.012211921624839306\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.013693457469344139\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.02866530418395996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ATE_BERT_Dropout_BiLSTM_Linear(BertModel.from_pretrained('bert-base-uncased'), dropout=0.3, bilstm_in_features=256, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "\n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ATE/SemEval16 - Task 5 - Restaurants/plots/bert_pt_do_bilstm_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.473221</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.439346</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.453845</td>\n",
       "      <td>376.056191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995535</td>\n",
       "      <td>0.995535</td>\n",
       "      <td>0.511154</td>\n",
       "      <td>0.995535</td>\n",
       "      <td>0.356073</td>\n",
       "      <td>0.995535</td>\n",
       "      <td>0.372995</td>\n",
       "      <td>369.115474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.480656</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.464795</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.472240</td>\n",
       "      <td>381.904849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.496419</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.500367</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.498375</td>\n",
       "      <td>380.993049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.466067</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.452757</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.459024</td>\n",
       "      <td>372.416976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.996555</td>\n",
       "      <td>0.996555</td>\n",
       "      <td>0.826181</td>\n",
       "      <td>0.996555</td>\n",
       "      <td>0.538250</td>\n",
       "      <td>0.996555</td>\n",
       "      <td>0.578448</td>\n",
       "      <td>369.571975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.470954</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.427095</td>\n",
       "      <td>0.995363</td>\n",
       "      <td>0.444711</td>\n",
       "      <td>368.585389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.996148</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>0.824313</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>0.540726</td>\n",
       "      <td>0.996148</td>\n",
       "      <td>0.537783</td>\n",
       "      <td>370.620469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.779856</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.633890</td>\n",
       "      <td>0.996223</td>\n",
       "      <td>0.606805</td>\n",
       "      <td>369.080026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995180</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>0.438210</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>0.354422</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>0.367819</td>\n",
       "      <td>368.632803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.995379               0.995379               0.473221            0.995379   \n",
       "1  0.995535               0.995535               0.511154            0.995535   \n",
       "2  0.995477               0.995477               0.480656            0.995477   \n",
       "3  0.996051               0.996051               0.496419            0.996051   \n",
       "4  0.995367               0.995367               0.466067            0.995367   \n",
       "5  0.996555               0.996555               0.826181            0.996555   \n",
       "6  0.995363               0.995363               0.470954            0.995363   \n",
       "7  0.996148               0.996148               0.824313            0.996148   \n",
       "8  0.996223               0.996223               0.779856            0.996223   \n",
       "9  0.995180               0.995180               0.438210            0.995180   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.439346        0.995379        0.453845      376.056191  \n",
       "1            0.356073        0.995535        0.372995      369.115474  \n",
       "2            0.464795        0.995477        0.472240      381.904849  \n",
       "3            0.500367        0.996051        0.498375      380.993049  \n",
       "4            0.452757        0.995367        0.459024      372.416976  \n",
       "5            0.538250        0.996555        0.578448      369.571975  \n",
       "6            0.427095        0.995363        0.444711      368.585389  \n",
       "7            0.540726        0.996148        0.537783      370.620469  \n",
       "8            0.633890        0.996223        0.606805      369.080026  \n",
       "9            0.354422        0.995180        0.367819      368.632803  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
