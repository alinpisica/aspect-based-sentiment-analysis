{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from ate_models.ATE_BERT_Dropout_Linear import ATE_BERT_Dropout_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "SEQ_LEN = 512\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_pre_trained_dropout_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_pre_trained_dropout_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            losses.append(loss_fn(outputs.view(-1, 3), tags_tensors.view(-1)).item())\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.192570686340332\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.042454976588487625\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.04388090968132019\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.024088304489850998\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.01759125106036663\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.016931114718317986\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.014734683558344841\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0239996537566185\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.026723774150013924\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.010271296836435795\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.015817493200302124\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.010078986175358295\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.020399663597345352\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.004418396390974522\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0047532920725643635\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008206851780414581\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.0044282954186201096\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009738890454173088\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.011500527150928974\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.00809198897331953\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.006810800172388554\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.002477716887369752\n",
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.171038031578064\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02819017507135868\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.019179068505764008\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.02177470549941063\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.028224866837263107\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.014470786787569523\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.029503853991627693\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.013978039845824242\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01937931962311268\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.009918727912008762\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.014215902425348759\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.015764255076646805\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.012348933145403862\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.020475808531045914\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00583463441580534\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.007769107818603516\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.009398050606250763\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.008684609085321426\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01680152676999569\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01227240264415741\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00958650466054678\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.012276849709451199\n",
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.537672996520996\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.04689027741551399\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.014641831628978252\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03805910795927048\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.0252685584127903\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02117021195590496\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.026822905987501144\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.006552782375365496\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.005510158836841583\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.0039025431033223867\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01569540426135063\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.01215373445302248\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.022336330264806747\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.014123735018074512\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.00491629634052515\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010290207341313362\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01867034286260605\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.011012527160346508\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.010341416113078594\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0045877909287810326\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00978302862495184\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007892902940511703\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.188460111618042\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.026318881660699844\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.058107197284698486\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.025366192683577538\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.04113234207034111\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.01522781141102314\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.008656303398311138\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.018105216324329376\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.009793960489332676\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.04270385578274727\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.015438699163496494\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.00604171073064208\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.009186943992972374\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02119549550116062\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0021575165446847677\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.010951364412903786\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008217133581638336\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0031577094923704863\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.012707858346402645\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0169722530990839\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.00508066825568676\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015467356890439987\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0641158819198608\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.02324184589087963\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.020957453176379204\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0180105771869421\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.010749067179858685\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03384963050484657\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.025944942608475685\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.028436217457056046\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0129597382619977\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01730290800333023\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02395518869161606\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.014834405854344368\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.0188314039260149\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.016801586374640465\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.018599657341837883\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.022060243412852287\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.004219633527100086\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0075836749747395515\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.0024099096190184355\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.0023152772337198257\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.004976849537342787\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.002942898077890277\n",
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.8651326894760132\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.029446108266711235\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.0300484299659729\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.015238354913890362\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03165223449468613\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02972283959388733\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.017483316361904144\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.022083768621087074\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.021037252619862556\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.013210548087954521\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.006007470656186342\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.015384811908006668\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.012562699615955353\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0072997254319489\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.012620702385902405\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.015607111155986786\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.016807490959763527\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.008345354348421097\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.006794022861868143\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.015141986310482025\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0047072917222976685\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007802026811987162\n",
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0391385555267334\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.028858697041869164\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.013031433336436749\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.03841458261013031\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.012808270752429962\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.01224095094949007\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.018742693588137627\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0265835989266634\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.015510650351643562\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.012118883430957794\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.018043871968984604\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.020443761721253395\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.006740843411535025\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.006165206898003817\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.005988296587020159\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.01305370219051838\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.00916282832622528\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.0033360342495143414\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.005665093194693327\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.021975018084049225\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.004486883990466595\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.006521403789520264\n",
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.9485997557640076\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.039605505764484406\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.018801525235176086\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.021458476781845093\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.015887200832366943\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.015551377087831497\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.01778589002788067\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.012075293809175491\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.015106751583516598\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.013202455826103687\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.0072250268422067165\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.00637136260047555\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015217496082186699\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.01450147945433855\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.0048731472343206406\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.014143180102109909\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02867637202143669\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.007718993816524744\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.004871980752795935\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.011333170346915722\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010991730727255344\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.005353489425033331\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 0.7072255611419678\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.04757004603743553\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.018903234973549843\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.023027777671813965\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.015847792848944664\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.019361237064003944\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.005674923770129681\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.020671887323260307\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01888129860162735\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.011264900676906109\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.003334455657750368\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.004062462132424116\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.018241064622998238\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.009698792360723019\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.005713209975510836\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.012564987875521183\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.010120615363121033\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.013433043844997883\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.006812909618020058\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.009263763204216957\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.0029253168031573296\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.007751647848635912\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1228536367416382\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.03194251284003258\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.027750510722398758\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.01475430652499199\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.003744774032384157\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.015425224788486958\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.025736160576343536\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.014703287743031979\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.01722387596964836\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.023177042603492737\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.029681723564863205\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.011625811457633972\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015352651476860046\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.027667831629514694\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.010089957155287266\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.008620630018413067\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.014711051248013973\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.005121449939906597\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.009473180398344994\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.005995593965053558\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.016224263235926628\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.010961569845676422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ATE_BERT_Dropout_Linear(BertModel.from_pretrained('bert-base-uncased'), dropout=0.3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "    \n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ATE/SemEval16 - Task 5 - Restaurants/plots/bert_pt_dropout_linear_train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    outputs, targets, valid_losses = validation(model, validation_dataloader, torch.nn.CrossEntropyLoss())\n",
    "    plt.title(f'Valid Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(valid_losses)\n",
    "    plt.savefig(f'../../../results/ATE/SemEval16 - Task 5 - Restaurants/plots/bert_pt_dropout_linear_valid_loss_run_{i + 1}.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.bert, BERT_FINE_TUNED_OUTPUT)\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.769768</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.646236</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>333.847623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.752266</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.704952</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.710621</td>\n",
       "      <td>332.535915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.759255</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.620001</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.608690</td>\n",
       "      <td>332.555571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.741001</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.707137</td>\n",
       "      <td>0.997117</td>\n",
       "      <td>0.718545</td>\n",
       "      <td>332.509994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997305</td>\n",
       "      <td>0.997305</td>\n",
       "      <td>0.763772</td>\n",
       "      <td>0.997305</td>\n",
       "      <td>0.679450</td>\n",
       "      <td>0.997305</td>\n",
       "      <td>0.680584</td>\n",
       "      <td>332.306395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.723549</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.752048</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.733329</td>\n",
       "      <td>332.545011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.784276</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.700438</td>\n",
       "      <td>0.997266</td>\n",
       "      <td>0.702756</td>\n",
       "      <td>331.933245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.738814</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.730842</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.725397</td>\n",
       "      <td>331.677276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.799493</td>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.743991</td>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.756308</td>\n",
       "      <td>332.068794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.783911</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.663056</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.666251</td>\n",
       "      <td>332.704665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.997281               0.997281               0.769768            0.997281   \n",
       "1  0.997258               0.997258               0.752266            0.997258   \n",
       "2  0.996762               0.996762               0.759255            0.996762   \n",
       "3  0.997117               0.997117               0.741001            0.997117   \n",
       "4  0.997305               0.997305               0.763772            0.997305   \n",
       "5  0.997219               0.997219               0.723549            0.997219   \n",
       "6  0.997266               0.997266               0.784276            0.997266   \n",
       "7  0.997234               0.997234               0.738814            0.997234   \n",
       "8  0.997871               0.997871               0.799493            0.997871   \n",
       "9  0.997352               0.997352               0.783911            0.997352   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.646236        0.997281        0.668023      333.847623  \n",
       "1            0.704952        0.997258        0.710621      332.535915  \n",
       "2            0.620001        0.996762        0.608690      332.555571  \n",
       "3            0.707137        0.997117        0.718545      332.509994  \n",
       "4            0.679450        0.997305        0.680584      332.306395  \n",
       "5            0.752048        0.997219        0.733329      332.545011  \n",
       "6            0.700438        0.997266        0.702756      331.933245  \n",
       "7            0.730842        0.997234        0.725397      331.677276  \n",
       "8            0.743991        0.997871        0.756308      332.068794  \n",
       "9            0.663056        0.997352        0.666251      332.704665  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
