{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from InputDataset import InputDataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch import cuda\n",
    "\n",
    "from ate_models.ATE_BERT_Dropout_CNN_BiLSTM_Linear import ATE_BERT_Dropout_CNN_BiLSTM_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "logging.set_verbosity_error() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060 SUPER\n",
      "Memory: 8 GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ATE_SemEval16_Restaurants_train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(DATASET)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>iob_aspect_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>[Judging, from, previous, posts, this, used, t...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We, there were four of us, arrived at noon - t...</td>\n",
       "      <td>[We, ,, there, were, four, of, us, ,, arrived,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They never brought us complimentary noodles, i...</td>\n",
       "      <td>[They, never, brought, us, complimentary, nood...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The food was lousy - too sweet or too salty an...</td>\n",
       "      <td>[The, food, was, lousy, -, too, sweet, or, too...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Judging from previous posts this used to be a ...   \n",
       "1  We, there were four of us, arrived at noon - t...   \n",
       "2  They never brought us complimentary noodles, i...   \n",
       "3  The food was lousy - too sweet or too salty an...   \n",
       "4  The food was lousy - too sweet or too salty an...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Judging, from, previous, posts, this, used, t...   \n",
       "1  [We, ,, there, were, four, of, us, ,, arrived,...   \n",
       "2  [They, never, brought, us, complimentary, nood...   \n",
       "3  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "4  [The, food, was, lousy, -, too, sweet, or, too...   \n",
       "\n",
       "                                     iob_aspect_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "NO_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_FINE_TUNED_PATH = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_512.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/models/bert_fine_tuned_dropout_cnn_bilstm_linear_512.pth'\n",
    "STATS_OUTPUT = '../../../results/ATE/SemEval16 - Task 5 - Restaurants/stats/bert_fine_tuned_dropout_cnn_bilstm_linear_512.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(ids_tensors[0])), 0)(ids_tensors[0])\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True).to(device)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors[0] = torch.nn.ConstantPad1d((0, SEQ_LEN - len(tags_tensors[0])), 0)(tags_tensors[0])\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True).to(device)\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long).to(device)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1).to(device)\n",
    "    \n",
    "    return ids_tensors, tags_tensors, masks_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_fn, optimizer, dataloader):\n",
    "    model.train()\n",
    "\n",
    "    dataloader_len = len(dataloader)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for _,data in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ids_tensors, tags_tensors, masks_tensors = data\n",
    "\n",
    "        outputs = model(ids_tensors, masks_tensors)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, 3), tags_tensors.view(-1))\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _ % (dataloader_len // 10) == 0:\n",
    "            print(f\"Epoch: {epoch}/{EPOCHS}, Batch: {_}/{dataloader_len}, Loss: {loss.item()}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            ids_tensors, tags_tensors, masks_tensors = data\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            outputs = model(ids_tensors, masks_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "            fin_outputs += list([int(p) for pred in predictions for p in pred])\n",
    "            fin_targets += list([int(tag) for tags_tensor in tags_tensors for tag in tags_tensor])\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['accuracy','precision_score_micro','precision_score_macro','recall_score_micro','recall_score_macro','f1_score_micro','f1_score_macro', 'execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0976605415344238\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.6836255788803101\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.273844838142395\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.136262908577919\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.09060438722372055\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.07716764509677887\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.07023317366838455\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.06357183307409286\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04533011093735695\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.05007601156830788\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.05163704231381416\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.04371737688779831\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.04019439220428467\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.03511502966284752\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.03373675420880318\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.029965728521347046\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02951880916953087\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.03055153228342533\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.03238974139094353\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.025323335081338882\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.01935071311891079\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.017445353791117668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1350507736206055\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.4459030330181122\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.11481458693742752\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06066460907459259\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.06281039863824844\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.028407763689756393\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02652217075228691\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02467682771384716\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04064683988690376\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.016591107472777367\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02181858941912651\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.022068694233894348\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.028483837842941284\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.013318856246769428\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02533433400094509\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0393470823764801\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015824107453227043\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.010489302687346935\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.018604470416903496\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01100181508809328\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.028143590316176414\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.019417446106672287\n",
      "Run 3/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1118073463439941\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5771748423576355\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.1750790774822235\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07634536921977997\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05567316710948944\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.047274213284254074\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.036878377199172974\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.01965145766735077\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.015836836770176888\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02211817353963852\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.022371280938386917\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.018039314076304436\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.013072648085653782\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.019079411402344704\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.033164143562316895\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.024426300078630447\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02241319604218006\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019401831552386284\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01864103600382805\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.01910402812063694\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.014447985216975212\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.015044729225337505\n",
      "Run 4/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1091078519821167\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.476190447807312\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.12300138175487518\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.057574763894081116\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.058065015822649\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.02696908637881279\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02803226001560688\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0270868930965662\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.014106068760156631\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.017766283825039864\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.015536459162831306\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.013938231393694878\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.015136276371777058\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.027421701699495316\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.030210208147764206\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.011391994543373585\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.023482143878936768\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.02778724581003189\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.019096484407782555\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.030274955555796623\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.03035242296755314\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.010423202998936176\n",
      "Run 5/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0523741245269775\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.3434881567955017\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.15183575451374054\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.07172222435474396\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05405807122588158\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.039574939757585526\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03308205306529999\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.024142201989889145\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.022192789241671562\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01853070594370365\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.030420811846852303\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.019840441644191742\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.026348784565925598\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.011325870640575886\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.02332625724375248\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.013836384750902653\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.01824394054710865\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.019167233258485794\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.01474788598716259\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019574029371142387\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.011016526259481907\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.025642871856689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 6/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1332134008407593\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.5023646354675293\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.14383405447006226\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06475847214460373\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03894929587841034\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.03647876903414726\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.030374394729733467\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.044236261397600174\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.02048378810286522\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.01951773837208748\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.02915814146399498\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.017862048000097275\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.024895479902625084\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.024444056674838066\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.015969619154930115\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.032181400805711746\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.008789229206740856\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.04117729887366295\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.04198158159852028\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019825858995318413\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.011952858418226242\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.01569771207869053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 7/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.144788384437561\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.39965352416038513\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13667304813861847\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.06583153456449509\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.05569930374622345\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.05044631287455559\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.04838879778981209\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.02809957228600979\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.0217494685202837\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.02150377631187439\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.027784276753664017\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.028157738968729973\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.038965001702308655\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.0208070520311594\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.019859030842781067\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.0360417440533638\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.015347005799412727\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.009846854954957962\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.023372279480099678\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.012034454382956028\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.016323504969477654\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.009574773721396923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apps\\Anaconda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 8/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.1093993186950684\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.42232051491737366\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.10673917829990387\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.060128431767225266\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.040338657796382904\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.030302824452519417\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.02971889078617096\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.03893318027257919\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.04369034618139267\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.016320399940013885\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.046475961804389954\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.028368595987558365\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.029555896297097206\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.02993716299533844\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.011598318815231323\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.030187392607331276\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.018613062798976898\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.016945140436291695\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.022710898891091347\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.019656619057059288\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.014238851144909859\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.016374707221984863\n",
      "Run 9/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.0460119247436523\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.48306310176849365\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.11732414364814758\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.053752925246953964\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03738612309098244\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.029104048386216164\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.03799358010292053\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.0233335979282856\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.020335284993052483\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.011869557201862335\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.01797644980251789\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.028275908902287483\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.010135437361896038\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.008078623563051224\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.020102225244045258\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.03842892497777939\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.021093707531690598\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.017434099689126015\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.02628590166568756\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.021120833232998848\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.010295087471604347\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.012124842964112759\n",
      "Run 10/10\n",
      "Epoch: 0/2, Batch: 0/501, Loss: 1.047113299369812\n",
      "Epoch: 0/2, Batch: 50/501, Loss: 0.41397199034690857\n",
      "Epoch: 0/2, Batch: 100/501, Loss: 0.13815945386886597\n",
      "Epoch: 0/2, Batch: 150/501, Loss: 0.0650787279009819\n",
      "Epoch: 0/2, Batch: 200/501, Loss: 0.03870885446667671\n",
      "Epoch: 0/2, Batch: 250/501, Loss: 0.04295426607131958\n",
      "Epoch: 0/2, Batch: 300/501, Loss: 0.043979302048683167\n",
      "Epoch: 0/2, Batch: 350/501, Loss: 0.023289170116186142\n",
      "Epoch: 0/2, Batch: 400/501, Loss: 0.021107586100697517\n",
      "Epoch: 0/2, Batch: 450/501, Loss: 0.025052834302186966\n",
      "Epoch: 0/2, Batch: 500/501, Loss: 0.018387094140052795\n",
      "Epoch: 1/2, Batch: 0/501, Loss: 0.03412448987364769\n",
      "Epoch: 1/2, Batch: 50/501, Loss: 0.038845282047986984\n",
      "Epoch: 1/2, Batch: 100/501, Loss: 0.032792724668979645\n",
      "Epoch: 1/2, Batch: 150/501, Loss: 0.029156630858778954\n",
      "Epoch: 1/2, Batch: 200/501, Loss: 0.011895707808434963\n",
      "Epoch: 1/2, Batch: 250/501, Loss: 0.02332199737429619\n",
      "Epoch: 1/2, Batch: 300/501, Loss: 0.015431915409862995\n",
      "Epoch: 1/2, Batch: 350/501, Loss: 0.021419715136289597\n",
      "Epoch: 1/2, Batch: 400/501, Loss: 0.012891757301986217\n",
      "Epoch: 1/2, Batch: 450/501, Loss: 0.02148667722940445\n",
      "Epoch: 1/2, Batch: 500/501, Loss: 0.032617393881082535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(NO_RUNS):\n",
    "    # clear cache cuda\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Run {i + 1}/{NO_RUNS}\")\n",
    "\n",
    "    train_dataset = df.sample(frac=TRAIN_SPLIT)\n",
    "    test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    training_set = InputDataset(train_dataset, tokenizer)\n",
    "    testing_set = InputDataset(test_dataset, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        training_set,\n",
    "        sampler = RandomSampler(train_dataset),\n",
    "        batch_size = TRAIN_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        testing_set,\n",
    "        sampler = SequentialSampler(testing_set),\n",
    "        batch_size = VALID_BATCH_SIZE,\n",
    "        drop_last = True,\n",
    "        collate_fn=create_mini_batch\n",
    "    )\n",
    "\n",
    "    model = ATE_BERT_Dropout_CNN_BiLSTM_Linear(torch.load(BERT_FINE_TUNED_PATH), bert_seq_len=SEQ_LEN, dropout=0.3, bilstm_in_features=256, conv_out_channels=SEQ_LEN, conv_kernel_size=3, no_out_labels=3, device=device).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = train(epoch, model, loss_fn, optimizer, train_dataloader)\n",
    "\n",
    "        train_losses += losses\n",
    "\n",
    "    outputs, targets = validation(model, validation_dataloader)\n",
    "\n",
    "    plt.title(f'Train Loss for run {i + 1}/{NO_RUNS}')\n",
    "    plt.plot(train_losses)\n",
    "    plt.savefig(f'../../../results/ATE/SemEval16 - Task 5 - Restaurants/plots/bert_ft_do_cnn_bilstm_lin/train_loss_run_{i + 1}.png')\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "    accuracy = accuracy_score(targets, outputs)\n",
    "    precision_score_micro = precision_score(targets, outputs, average='micro')\n",
    "    precision_score_macro = precision_score(targets, outputs, average='macro')\n",
    "    recall_score_micro = recall_score(targets, outputs, average='micro')\n",
    "    recall_score_macro = recall_score(targets, outputs, average='macro')\n",
    "    f1_score_micro = f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = f1_score(targets, outputs, average='macro')\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    results.loc[i] = [accuracy,precision_score_micro,precision_score_macro,recall_score_micro,recall_score_macro,f1_score_micro,f1_score_macro, execution_time]\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model, MODEL_OUTPUT)\n",
    "\n",
    "    del train_dataset\n",
    "    del test_dataset\n",
    "    del training_set\n",
    "    del testing_set\n",
    "    del model\n",
    "    del loss_fn\n",
    "    del optimizer\n",
    "    del outputs\n",
    "    del targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_score_micro</th>\n",
       "      <th>precision_score_macro</th>\n",
       "      <th>recall_score_micro</th>\n",
       "      <th>recall_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995219</td>\n",
       "      <td>0.995219</td>\n",
       "      <td>0.331740</td>\n",
       "      <td>0.995219</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.995219</td>\n",
       "      <td>0.332535</td>\n",
       "      <td>378.079059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.995211</td>\n",
       "      <td>0.995211</td>\n",
       "      <td>0.549511</td>\n",
       "      <td>0.995211</td>\n",
       "      <td>0.349132</td>\n",
       "      <td>0.995211</td>\n",
       "      <td>0.361231</td>\n",
       "      <td>372.331963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.591409</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.363667</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.386250</td>\n",
       "      <td>369.907994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.576180</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.444683</td>\n",
       "      <td>0.995016</td>\n",
       "      <td>0.469607</td>\n",
       "      <td>370.942109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.449635</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.390058</td>\n",
       "      <td>0.995578</td>\n",
       "      <td>0.409226</td>\n",
       "      <td>369.574724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.994988</td>\n",
       "      <td>0.994988</td>\n",
       "      <td>0.458146</td>\n",
       "      <td>0.994988</td>\n",
       "      <td>0.351945</td>\n",
       "      <td>0.994988</td>\n",
       "      <td>0.364967</td>\n",
       "      <td>369.602218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.432715</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.348859</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.359446</td>\n",
       "      <td>370.868318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.620380</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.367451</td>\n",
       "      <td>0.995367</td>\n",
       "      <td>0.391520</td>\n",
       "      <td>367.454077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.653608</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.353087</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.369785</td>\n",
       "      <td>367.983384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.567176</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.359050</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.378929</td>\n",
       "      <td>361.873867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  precision_score_micro  precision_score_macro  recall_score_micro  \\\n",
       "0  0.995219               0.995219               0.331740            0.995219   \n",
       "1  0.995211               0.995211               0.549511            0.995211   \n",
       "2  0.994895               0.994895               0.591409            0.994895   \n",
       "3  0.995016               0.995016               0.576180            0.995016   \n",
       "4  0.995578               0.995578               0.449635            0.995578   \n",
       "5  0.994988               0.994988               0.458146            0.994988   \n",
       "6  0.994938               0.994938               0.432715            0.994938   \n",
       "7  0.995367               0.995367               0.620380            0.995367   \n",
       "8  0.995145               0.995145               0.653608            0.995145   \n",
       "9  0.994598               0.994598               0.567176            0.994598   \n",
       "\n",
       "   recall_score_macro  f1_score_micro  f1_score_macro  execution_time  \n",
       "0            0.333333        0.995219        0.332535      378.079059  \n",
       "1            0.349132        0.995211        0.361231      372.331963  \n",
       "2            0.363667        0.994895        0.386250      369.907994  \n",
       "3            0.444683        0.995016        0.469607      370.942109  \n",
       "4            0.390058        0.995578        0.409226      369.574724  \n",
       "5            0.351945        0.994988        0.364967      369.602218  \n",
       "6            0.348859        0.994938        0.359446      370.868318  \n",
       "7            0.367451        0.995367        0.391520      367.454077  \n",
       "8            0.353087        0.995145        0.369785      367.983384  \n",
       "9            0.359050        0.994598        0.378929      361.873867  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(STATS_OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7b70e5470c1caae179898b9726485c258ababa2b5a8278be4bb974e3d5af9cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
